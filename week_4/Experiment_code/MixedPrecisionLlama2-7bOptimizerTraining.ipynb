{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbba63db-a710-4702-9b30-a217ed938dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from torch.amp import autocast, GradScaler\n",
    "from pytorch_memlab import MemReporter\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdd6f8a9-9a7d-4c83-a478-29acdcf1d5ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a9501b0932541198a6f14028e7425b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==初始化一下==\n",
      "==OptimizerMemoryUsage==\n",
      "Element type                                            Size  Used MEM\n",
      "-------------------------------------------------------------------------------\n",
      "Storage on cpu\n",
      "Tensor0                                         (4096, 4096)    64.00M\n",
      "Tensor1                                                 (1,)   512.00B\n",
      "Tensor2                                         (4096, 4096)    64.00M\n",
      "Tensor3                                         (4096, 4096)    64.00M\n",
      "Tensor4                                                 (1,)   512.00B\n",
      "Tensor5                                        (11008, 4096)   172.00M\n",
      "Tensor6                                        (11008, 4096)   172.00M\n",
      "Tensor7                                                 (1,)   512.00B\n",
      "Tensor8                                        (11008, 4096)   172.00M\n",
      "Tensor9                                        (11008, 4096)   172.00M\n",
      "Tensor10                                                (1,)   512.00B\n",
      "Tensor11                                       (4096, 11008)   172.00M\n",
      "Tensor12                                       (4096, 11008)   172.00M\n",
      "Tensor13                                                (1,)   512.00B\n",
      "Tensor14                                             (4096,)    16.00K\n",
      "Tensor15                                             (4096,)    16.00K\n",
      "Tensor16                                                (1,)   512.00B\n",
      "Tensor17                                             (4096,)    16.00K\n",
      "Tensor18                                             (4096,)    16.00K\n",
      "Tensor19                                                (1,)   512.00B\n",
      "Tensor20                                        (4096, 4096)    64.00M\n",
      "Tensor21                                        (4096, 4096)    64.00M\n",
      "Tensor22                                                (1,)   512.00B\n",
      "Tensor23                                        (4096, 4096)    64.00M\n",
      "Tensor24                                        (4096, 4096)    64.00M\n",
      "Tensor25                                                (1,)   512.00B\n",
      "Tensor26                                        (4096, 4096)    64.00M\n",
      "Tensor27                                        (4096, 4096)    64.00M\n",
      "Tensor28                                                (1,)   512.00B\n",
      "Tensor29                                        (4096, 4096)    64.00M\n",
      "Tensor30                                        (4096, 4096)    64.00M\n",
      "Tensor31                                                (1,)   512.00B\n",
      "Tensor32                                       (11008, 4096)   172.00M\n",
      "Tensor33                                       (11008, 4096)   172.00M\n",
      "Tensor34                                                (1,)   512.00B\n",
      "Tensor35                                       (11008, 4096)   172.00M\n",
      "Tensor36                                       (11008, 4096)   172.00M\n",
      "Tensor37                                                (1,)   512.00B\n",
      "Tensor38                                       (4096, 11008)   172.00M\n",
      "Tensor39                                       (4096, 11008)   172.00M\n",
      "Tensor40                                                (1,)   512.00B\n",
      "Tensor41                                             (4096,)    16.00K\n",
      "Tensor42                                             (4096,)    16.00K\n",
      "Tensor43                                                (1,)   512.00B\n",
      "Tensor44                                             (4096,)    16.00K\n",
      "Tensor45                                             (4096,)    16.00K\n",
      "Tensor46                                                (1,)   512.00B\n",
      "Tensor47                                             (4096,)    16.00K\n",
      "Tensor48                                             (4096,)    16.00K\n",
      "Tensor49                                                (1,)   512.00B\n",
      "Tensor50                                       (32000, 4096)   500.00M\n",
      "Tensor51                                       (32000, 4096)   500.00M\n",
      "lm_head.weight                                 (32000, 4096)   500.00M\n",
      "lm_head.weight.grad                            (32000, 4096)   500.00M\n",
      "Tensor52                                               (64,)   512.00B\n",
      "model.embed_tokens.weight                      (32000, 4096)   500.00M\n",
      "model.embed_tokens.weight.grad                 (32000, 4096)   500.00M\n",
      "model.norm.weight                                    (4096,)    16.00K\n",
      "model.norm.weight.grad                               (4096,)    16.00K\n",
      "model.layers.0.input_layernorm.weight                (4096,)    16.00K\n",
      "model.layers.0.input_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.0.post_attention_layernorm.weight             (4096,)    16.00K\n",
      "model.layers.0.post_attention_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.1.input_layernorm.weight                (4096,)    16.00K\n",
      "model.layers.1.input_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.1.post_attention_layernorm.weight             (4096,)    16.00K\n",
      "model.layers.1.post_attention_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.2.input_layernorm.weight                (4096,)    16.00K\n",
      "model.layers.2.input_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.2.post_attention_layernorm.weight             (4096,)    16.00K\n",
      "model.layers.2.post_attention_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.3.input_layernorm.weight                (4096,)    16.00K\n",
      "model.layers.3.input_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.3.post_attention_layernorm.weight             (4096,)    16.00K\n",
      "model.layers.3.post_attention_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.4.input_layernorm.weight                (4096,)    16.00K\n",
      "model.layers.4.input_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.4.post_attention_layernorm.weight             (4096,)    16.00K\n",
      "model.layers.4.post_attention_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.5.input_layernorm.weight                (4096,)    16.00K\n",
      "model.layers.5.input_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.5.post_attention_layernorm.weight             (4096,)    16.00K\n",
      "model.layers.5.post_attention_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.6.input_layernorm.weight                (4096,)    16.00K\n",
      "model.layers.6.input_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.6.post_attention_layernorm.weight             (4096,)    16.00K\n",
      "model.layers.6.post_attention_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.7.input_layernorm.weight                (4096,)    16.00K\n",
      "model.layers.7.input_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.7.post_attention_layernorm.weight             (4096,)    16.00K\n",
      "model.layers.7.post_attention_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.8.input_layernorm.weight                (4096,)    16.00K\n",
      "model.layers.8.input_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.8.post_attention_layernorm.weight             (4096,)    16.00K\n",
      "model.layers.8.post_attention_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.9.input_layernorm.weight                (4096,)    16.00K\n",
      "model.layers.9.input_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.9.post_attention_layernorm.weight             (4096,)    16.00K\n",
      "model.layers.9.post_attention_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.10.input_layernorm.weight               (4096,)    16.00K\n",
      "model.layers.10.input_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.10.post_attention_layernorm.weight             (4096,)    16.00K\n",
      "model.layers.10.post_attention_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.11.input_layernorm.weight               (4096,)    16.00K\n",
      "model.layers.11.input_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.11.post_attention_layernorm.weight             (4096,)    16.00K\n",
      "model.layers.11.post_attention_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.12.input_layernorm.weight               (4096,)    16.00K\n",
      "model.layers.12.input_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.12.post_attention_layernorm.weight             (4096,)    16.00K\n",
      "model.layers.12.post_attention_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.13.input_layernorm.weight               (4096,)    16.00K\n",
      "model.layers.13.input_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.13.post_attention_layernorm.weight             (4096,)    16.00K\n",
      "model.layers.13.post_attention_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.14.input_layernorm.weight               (4096,)    16.00K\n",
      "model.layers.14.input_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.14.post_attention_layernorm.weight             (4096,)    16.00K\n",
      "model.layers.14.post_attention_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.15.input_layernorm.weight               (4096,)    16.00K\n",
      "model.layers.15.input_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.15.post_attention_layernorm.weight             (4096,)    16.00K\n",
      "model.layers.15.post_attention_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.16.input_layernorm.weight               (4096,)    16.00K\n",
      "model.layers.16.input_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.16.post_attention_layernorm.weight             (4096,)    16.00K\n",
      "model.layers.16.post_attention_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.17.input_layernorm.weight               (4096,)    16.00K\n",
      "model.layers.17.input_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.17.post_attention_layernorm.weight             (4096,)    16.00K\n",
      "model.layers.17.post_attention_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.18.input_layernorm.weight               (4096,)    16.00K\n",
      "model.layers.18.input_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.18.post_attention_layernorm.weight             (4096,)    16.00K\n",
      "model.layers.18.post_attention_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.19.input_layernorm.weight               (4096,)    16.00K\n",
      "model.layers.19.input_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.19.post_attention_layernorm.weight             (4096,)    16.00K\n",
      "model.layers.19.post_attention_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.20.input_layernorm.weight               (4096,)    16.00K\n",
      "model.layers.20.input_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.20.post_attention_layernorm.weight             (4096,)    16.00K\n",
      "model.layers.20.post_attention_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.21.input_layernorm.weight               (4096,)    16.00K\n",
      "model.layers.21.input_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.21.post_attention_layernorm.weight             (4096,)    16.00K\n",
      "model.layers.21.post_attention_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.22.input_layernorm.weight               (4096,)    16.00K\n",
      "model.layers.22.input_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.22.post_attention_layernorm.weight             (4096,)    16.00K\n",
      "model.layers.22.post_attention_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.23.input_layernorm.weight               (4096,)    16.00K\n",
      "model.layers.23.input_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.23.post_attention_layernorm.weight             (4096,)    16.00K\n",
      "model.layers.23.post_attention_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.24.input_layernorm.weight               (4096,)    16.00K\n",
      "model.layers.24.input_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.24.post_attention_layernorm.weight             (4096,)    16.00K\n",
      "model.layers.24.post_attention_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.25.input_layernorm.weight               (4096,)    16.00K\n",
      "model.layers.25.input_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.25.post_attention_layernorm.weight             (4096,)    16.00K\n",
      "model.layers.25.post_attention_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.26.input_layernorm.weight               (4096,)    16.00K\n",
      "model.layers.26.input_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.26.post_attention_layernorm.weight             (4096,)    16.00K\n",
      "model.layers.26.post_attention_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.27.input_layernorm.weight               (4096,)    16.00K\n",
      "model.layers.27.input_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.27.post_attention_layernorm.weight             (4096,)    16.00K\n",
      "model.layers.27.post_attention_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.28.input_layernorm.weight               (4096,)    16.00K\n",
      "model.layers.28.input_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.28.post_attention_layernorm.weight             (4096,)    16.00K\n",
      "model.layers.28.post_attention_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.29.input_layernorm.weight               (4096,)    16.00K\n",
      "model.layers.29.input_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.29.post_attention_layernorm.weight             (4096,)    16.00K\n",
      "model.layers.29.post_attention_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.30.input_layernorm.weight               (4096,)    16.00K\n",
      "model.layers.30.input_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.30.post_attention_layernorm.weight             (4096,)    16.00K\n",
      "model.layers.30.post_attention_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.31.input_layernorm.weight               (4096,)    16.00K\n",
      "model.layers.31.input_layernorm.weight.grad             (4096,)    16.00K\n",
      "model.layers.31.post_attention_layernorm.weight             (4096,)    16.00K\n",
      "model.layers.31.post_attention_layernorm.weight.grad             (4096,)    16.00K\n",
      "Tensor53                                               (64,)   512.00B\n",
      "Tensor54                                               (64,)   512.00B\n",
      "Tensor55                                               (64,)   512.00B\n",
      "Tensor56                                               (64,)   512.00B\n",
      "Tensor57                                               (64,)   512.00B\n",
      "Tensor58                                               (64,)   512.00B\n",
      "Tensor59                                               (64,)   512.00B\n",
      "Tensor60                                               (64,)   512.00B\n",
      "Tensor61                                               (64,)   512.00B\n",
      "Tensor62                                               (64,)   512.00B\n",
      "Tensor63                                               (64,)   512.00B\n",
      "Tensor64                                               (64,)   512.00B\n",
      "Tensor65                                               (64,)   512.00B\n",
      "Tensor66                                               (64,)   512.00B\n",
      "Tensor67                                               (64,)   512.00B\n",
      "Tensor68                                               (64,)   512.00B\n",
      "Tensor69                                               (64,)   512.00B\n",
      "Tensor70                                               (64,)   512.00B\n",
      "Tensor71                                               (64,)   512.00B\n",
      "Tensor72                                               (64,)   512.00B\n",
      "Tensor73                                               (64,)   512.00B\n",
      "Tensor74                                               (64,)   512.00B\n",
      "Tensor75                                               (64,)   512.00B\n",
      "Tensor76                                               (64,)   512.00B\n",
      "Tensor77                                               (64,)   512.00B\n",
      "Tensor78                                               (64,)   512.00B\n",
      "Tensor79                                               (64,)   512.00B\n",
      "Tensor80                                               (64,)   512.00B\n",
      "Tensor81                                               (64,)   512.00B\n",
      "Tensor82                                               (64,)   512.00B\n",
      "Tensor83                                               (64,)   512.00B\n",
      "Tensor84                                               (64,)   512.00B\n",
      "model.layers.0.self_attn.q_proj.weight          (4096, 4096)    64.00M\n",
      "model.layers.0.self_attn.q_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.0.self_attn.k_proj.weight          (4096, 4096)    64.00M\n",
      "model.layers.0.self_attn.k_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.0.self_attn.v_proj.weight          (4096, 4096)    64.00M\n",
      "model.layers.0.self_attn.v_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.0.self_attn.o_proj.weight          (4096, 4096)    64.00M\n",
      "model.layers.0.self_attn.o_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.0.mlp.gate_proj.weight            (11008, 4096)   172.00M\n",
      "model.layers.0.mlp.gate_proj.weight.grad       (11008, 4096)   172.00M\n",
      "model.layers.0.mlp.up_proj.weight              (11008, 4096)   172.00M\n",
      "model.layers.0.mlp.up_proj.weight.grad         (11008, 4096)   172.00M\n",
      "model.layers.0.mlp.down_proj.weight            (4096, 11008)   172.00M\n",
      "model.layers.0.mlp.down_proj.weight.grad       (4096, 11008)   172.00M\n",
      "model.layers.1.self_attn.q_proj.weight          (4096, 4096)    64.00M\n",
      "model.layers.1.self_attn.q_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.1.self_attn.k_proj.weight          (4096, 4096)    64.00M\n",
      "model.layers.1.self_attn.k_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.1.self_attn.v_proj.weight          (4096, 4096)    64.00M\n",
      "model.layers.1.self_attn.v_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.1.self_attn.o_proj.weight          (4096, 4096)    64.00M\n",
      "model.layers.1.self_attn.o_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.1.mlp.gate_proj.weight            (11008, 4096)   172.00M\n",
      "model.layers.1.mlp.gate_proj.weight.grad       (11008, 4096)   172.00M\n",
      "model.layers.1.mlp.up_proj.weight              (11008, 4096)   172.00M\n",
      "model.layers.1.mlp.up_proj.weight.grad         (11008, 4096)   172.00M\n",
      "model.layers.1.mlp.down_proj.weight            (4096, 11008)   172.00M\n",
      "model.layers.1.mlp.down_proj.weight.grad       (4096, 11008)   172.00M\n",
      "model.layers.2.self_attn.q_proj.weight          (4096, 4096)    64.00M\n",
      "model.layers.2.self_attn.q_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.2.self_attn.k_proj.weight          (4096, 4096)    64.00M\n",
      "model.layers.2.self_attn.k_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.2.self_attn.v_proj.weight          (4096, 4096)    64.00M\n",
      "model.layers.2.self_attn.v_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.2.self_attn.o_proj.weight          (4096, 4096)    64.00M\n",
      "model.layers.2.self_attn.o_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.2.mlp.gate_proj.weight            (11008, 4096)   172.00M\n",
      "model.layers.2.mlp.gate_proj.weight.grad       (11008, 4096)   172.00M\n",
      "model.layers.2.mlp.up_proj.weight              (11008, 4096)   172.00M\n",
      "model.layers.2.mlp.up_proj.weight.grad         (11008, 4096)   172.00M\n",
      "model.layers.2.mlp.down_proj.weight            (4096, 11008)   172.00M\n",
      "model.layers.2.mlp.down_proj.weight.grad       (4096, 11008)   172.00M\n",
      "model.layers.3.self_attn.q_proj.weight          (4096, 4096)    64.00M\n",
      "model.layers.3.self_attn.q_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.3.self_attn.k_proj.weight          (4096, 4096)    64.00M\n",
      "model.layers.3.self_attn.k_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.3.self_attn.v_proj.weight          (4096, 4096)    64.00M\n",
      "model.layers.3.self_attn.v_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.3.self_attn.o_proj.weight          (4096, 4096)    64.00M\n",
      "model.layers.3.self_attn.o_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.3.mlp.gate_proj.weight            (11008, 4096)   172.00M\n",
      "model.layers.3.mlp.gate_proj.weight.grad       (11008, 4096)   172.00M\n",
      "model.layers.3.mlp.up_proj.weight              (11008, 4096)   172.00M\n",
      "model.layers.3.mlp.up_proj.weight.grad         (11008, 4096)   172.00M\n",
      "model.layers.3.mlp.down_proj.weight            (4096, 11008)   172.00M\n",
      "model.layers.3.mlp.down_proj.weight.grad       (4096, 11008)   172.00M\n",
      "model.layers.4.self_attn.q_proj.weight          (4096, 4096)    64.00M\n",
      "model.layers.4.self_attn.q_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.4.self_attn.k_proj.weight          (4096, 4096)    64.00M\n",
      "model.layers.4.self_attn.k_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.4.self_attn.v_proj.weight          (4096, 4096)    64.00M\n",
      "model.layers.4.self_attn.v_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.4.self_attn.o_proj.weight          (4096, 4096)    64.00M\n",
      "model.layers.4.self_attn.o_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.4.mlp.gate_proj.weight            (11008, 4096)   172.00M\n",
      "model.layers.4.mlp.gate_proj.weight.grad       (11008, 4096)   172.00M\n",
      "model.layers.4.mlp.up_proj.weight              (11008, 4096)   172.00M\n",
      "model.layers.4.mlp.up_proj.weight.grad         (11008, 4096)   172.00M\n",
      "model.layers.4.mlp.down_proj.weight            (4096, 11008)   172.00M\n",
      "model.layers.4.mlp.down_proj.weight.grad       (4096, 11008)   172.00M\n",
      "model.layers.5.self_attn.q_proj.weight          (4096, 4096)    64.00M\n",
      "model.layers.5.self_attn.q_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.5.self_attn.k_proj.weight          (4096, 4096)    64.00M\n",
      "model.layers.5.self_attn.k_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.5.self_attn.v_proj.weight          (4096, 4096)    64.00M\n",
      "model.layers.5.self_attn.v_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.5.self_attn.o_proj.weight          (4096, 4096)    64.00M\n",
      "model.layers.5.self_attn.o_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.5.mlp.gate_proj.weight            (11008, 4096)   172.00M\n",
      "model.layers.5.mlp.gate_proj.weight.grad       (11008, 4096)   172.00M\n",
      "model.layers.5.mlp.up_proj.weight              (11008, 4096)   172.00M\n",
      "model.layers.5.mlp.up_proj.weight.grad         (11008, 4096)   172.00M\n",
      "model.layers.5.mlp.down_proj.weight            (4096, 11008)   172.00M\n",
      "model.layers.5.mlp.down_proj.weight.grad       (4096, 11008)   172.00M\n",
      "model.layers.6.self_attn.q_proj.weight          (4096, 4096)    64.00M\n",
      "model.layers.6.self_attn.q_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.6.self_attn.k_proj.weight          (4096, 4096)    64.00M\n",
      "model.layers.6.self_attn.k_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.6.self_attn.v_proj.weight          (4096, 4096)    64.00M\n",
      "model.layers.6.self_attn.v_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.6.self_attn.o_proj.weight          (4096, 4096)    64.00M\n",
      "model.layers.6.self_attn.o_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.6.mlp.gate_proj.weight            (11008, 4096)   172.00M\n",
      "model.layers.6.mlp.gate_proj.weight.grad       (11008, 4096)   172.00M\n",
      "model.layers.6.mlp.up_proj.weight              (11008, 4096)   172.00M\n",
      "model.layers.6.mlp.up_proj.weight.grad         (11008, 4096)   172.00M\n",
      "model.layers.6.mlp.down_proj.weight            (4096, 11008)   172.00M\n",
      "model.layers.6.mlp.down_proj.weight.grad       (4096, 11008)   172.00M\n",
      "model.layers.7.self_attn.q_proj.weight          (4096, 4096)    64.00M\n",
      "model.layers.7.self_attn.q_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.7.self_attn.k_proj.weight          (4096, 4096)    64.00M\n",
      "model.layers.7.self_attn.k_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.7.self_attn.v_proj.weight          (4096, 4096)    64.00M\n",
      "model.layers.7.self_attn.v_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.7.self_attn.o_proj.weight          (4096, 4096)    64.00M\n",
      "model.layers.7.self_attn.o_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.7.mlp.gate_proj.weight            (11008, 4096)   172.00M\n",
      "model.layers.7.mlp.gate_proj.weight.grad       (11008, 4096)   172.00M\n",
      "model.layers.7.mlp.up_proj.weight              (11008, 4096)   172.00M\n",
      "model.layers.7.mlp.up_proj.weight.grad         (11008, 4096)   172.00M\n",
      "model.layers.7.mlp.down_proj.weight            (4096, 11008)   172.00M\n",
      "model.layers.7.mlp.down_proj.weight.grad       (4096, 11008)   172.00M\n",
      "model.layers.8.self_attn.q_proj.weight          (4096, 4096)    64.00M\n",
      "model.layers.8.self_attn.q_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.8.self_attn.k_proj.weight          (4096, 4096)    64.00M\n",
      "model.layers.8.self_attn.k_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.8.self_attn.v_proj.weight          (4096, 4096)    64.00M\n",
      "model.layers.8.self_attn.v_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.8.self_attn.o_proj.weight          (4096, 4096)    64.00M\n",
      "model.layers.8.self_attn.o_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.8.mlp.gate_proj.weight            (11008, 4096)   172.00M\n",
      "model.layers.8.mlp.gate_proj.weight.grad       (11008, 4096)   172.00M\n",
      "model.layers.8.mlp.up_proj.weight              (11008, 4096)   172.00M\n",
      "model.layers.8.mlp.up_proj.weight.grad         (11008, 4096)   172.00M\n",
      "model.layers.8.mlp.down_proj.weight            (4096, 11008)   172.00M\n",
      "model.layers.8.mlp.down_proj.weight.grad       (4096, 11008)   172.00M\n",
      "model.layers.9.self_attn.q_proj.weight          (4096, 4096)    64.00M\n",
      "model.layers.9.self_attn.q_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.9.self_attn.k_proj.weight          (4096, 4096)    64.00M\n",
      "model.layers.9.self_attn.k_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.9.self_attn.v_proj.weight          (4096, 4096)    64.00M\n",
      "model.layers.9.self_attn.v_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.9.self_attn.o_proj.weight          (4096, 4096)    64.00M\n",
      "model.layers.9.self_attn.o_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.9.mlp.gate_proj.weight            (11008, 4096)   172.00M\n",
      "model.layers.9.mlp.gate_proj.weight.grad       (11008, 4096)   172.00M\n",
      "model.layers.9.mlp.up_proj.weight              (11008, 4096)   172.00M\n",
      "model.layers.9.mlp.up_proj.weight.grad         (11008, 4096)   172.00M\n",
      "model.layers.9.mlp.down_proj.weight            (4096, 11008)   172.00M\n",
      "model.layers.9.mlp.down_proj.weight.grad       (4096, 11008)   172.00M\n",
      "model.layers.10.self_attn.q_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.10.self_attn.q_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.10.self_attn.k_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.10.self_attn.k_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.10.self_attn.v_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.10.self_attn.v_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.10.self_attn.o_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.10.self_attn.o_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.10.mlp.gate_proj.weight           (11008, 4096)   172.00M\n",
      "model.layers.10.mlp.gate_proj.weight.grad       (11008, 4096)   172.00M\n",
      "model.layers.10.mlp.up_proj.weight             (11008, 4096)   172.00M\n",
      "model.layers.10.mlp.up_proj.weight.grad        (11008, 4096)   172.00M\n",
      "model.layers.10.mlp.down_proj.weight           (4096, 11008)   172.00M\n",
      "model.layers.10.mlp.down_proj.weight.grad       (4096, 11008)   172.00M\n",
      "model.layers.11.self_attn.q_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.11.self_attn.q_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.11.self_attn.k_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.11.self_attn.k_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.11.self_attn.v_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.11.self_attn.v_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.11.self_attn.o_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.11.self_attn.o_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.11.mlp.gate_proj.weight           (11008, 4096)   172.00M\n",
      "model.layers.11.mlp.gate_proj.weight.grad       (11008, 4096)   172.00M\n",
      "model.layers.11.mlp.up_proj.weight             (11008, 4096)   172.00M\n",
      "model.layers.11.mlp.up_proj.weight.grad        (11008, 4096)   172.00M\n",
      "model.layers.11.mlp.down_proj.weight           (4096, 11008)   172.00M\n",
      "model.layers.11.mlp.down_proj.weight.grad       (4096, 11008)   172.00M\n",
      "model.layers.12.self_attn.q_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.12.self_attn.q_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.12.self_attn.k_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.12.self_attn.k_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.12.self_attn.v_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.12.self_attn.v_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.12.self_attn.o_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.12.self_attn.o_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.12.mlp.gate_proj.weight           (11008, 4096)   172.00M\n",
      "model.layers.12.mlp.gate_proj.weight.grad       (11008, 4096)   172.00M\n",
      "model.layers.12.mlp.up_proj.weight             (11008, 4096)   172.00M\n",
      "model.layers.12.mlp.up_proj.weight.grad        (11008, 4096)   172.00M\n",
      "model.layers.12.mlp.down_proj.weight           (4096, 11008)   172.00M\n",
      "model.layers.12.mlp.down_proj.weight.grad       (4096, 11008)   172.00M\n",
      "model.layers.13.self_attn.q_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.13.self_attn.q_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.13.self_attn.k_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.13.self_attn.k_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.13.self_attn.v_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.13.self_attn.v_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.13.self_attn.o_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.13.self_attn.o_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.13.mlp.gate_proj.weight           (11008, 4096)   172.00M\n",
      "model.layers.13.mlp.gate_proj.weight.grad       (11008, 4096)   172.00M\n",
      "model.layers.13.mlp.up_proj.weight             (11008, 4096)   172.00M\n",
      "model.layers.13.mlp.up_proj.weight.grad        (11008, 4096)   172.00M\n",
      "model.layers.13.mlp.down_proj.weight           (4096, 11008)   172.00M\n",
      "model.layers.13.mlp.down_proj.weight.grad       (4096, 11008)   172.00M\n",
      "model.layers.14.self_attn.q_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.14.self_attn.q_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.14.self_attn.k_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.14.self_attn.k_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.14.self_attn.v_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.14.self_attn.v_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.14.self_attn.o_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.14.self_attn.o_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.14.mlp.gate_proj.weight           (11008, 4096)   172.00M\n",
      "model.layers.14.mlp.gate_proj.weight.grad       (11008, 4096)   172.00M\n",
      "model.layers.14.mlp.up_proj.weight             (11008, 4096)   172.00M\n",
      "model.layers.14.mlp.up_proj.weight.grad        (11008, 4096)   172.00M\n",
      "model.layers.14.mlp.down_proj.weight           (4096, 11008)   172.00M\n",
      "model.layers.14.mlp.down_proj.weight.grad       (4096, 11008)   172.00M\n",
      "model.layers.15.self_attn.q_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.15.self_attn.q_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.15.self_attn.k_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.15.self_attn.k_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.15.self_attn.v_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.15.self_attn.v_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.15.self_attn.o_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.15.self_attn.o_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.15.mlp.gate_proj.weight           (11008, 4096)   172.00M\n",
      "model.layers.15.mlp.gate_proj.weight.grad       (11008, 4096)   172.00M\n",
      "model.layers.15.mlp.up_proj.weight             (11008, 4096)   172.00M\n",
      "model.layers.15.mlp.up_proj.weight.grad        (11008, 4096)   172.00M\n",
      "model.layers.15.mlp.down_proj.weight           (4096, 11008)   172.00M\n",
      "model.layers.15.mlp.down_proj.weight.grad       (4096, 11008)   172.00M\n",
      "model.layers.16.self_attn.q_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.16.self_attn.q_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.16.self_attn.k_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.16.self_attn.k_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.16.self_attn.v_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.16.self_attn.v_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.16.self_attn.o_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.16.self_attn.o_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.16.mlp.gate_proj.weight           (11008, 4096)   172.00M\n",
      "model.layers.16.mlp.gate_proj.weight.grad       (11008, 4096)   172.00M\n",
      "model.layers.16.mlp.up_proj.weight             (11008, 4096)   172.00M\n",
      "model.layers.16.mlp.up_proj.weight.grad        (11008, 4096)   172.00M\n",
      "model.layers.16.mlp.down_proj.weight           (4096, 11008)   172.00M\n",
      "model.layers.16.mlp.down_proj.weight.grad       (4096, 11008)   172.00M\n",
      "model.layers.17.self_attn.q_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.17.self_attn.q_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.17.self_attn.k_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.17.self_attn.k_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.17.self_attn.v_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.17.self_attn.v_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.17.self_attn.o_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.17.self_attn.o_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.17.mlp.gate_proj.weight           (11008, 4096)   172.00M\n",
      "model.layers.17.mlp.gate_proj.weight.grad       (11008, 4096)   172.00M\n",
      "model.layers.17.mlp.up_proj.weight             (11008, 4096)   172.00M\n",
      "model.layers.17.mlp.up_proj.weight.grad        (11008, 4096)   172.00M\n",
      "model.layers.17.mlp.down_proj.weight           (4096, 11008)   172.00M\n",
      "model.layers.17.mlp.down_proj.weight.grad       (4096, 11008)   172.00M\n",
      "model.layers.18.self_attn.q_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.18.self_attn.q_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.18.self_attn.k_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.18.self_attn.k_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.18.self_attn.v_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.18.self_attn.v_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.18.self_attn.o_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.18.self_attn.o_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.18.mlp.gate_proj.weight           (11008, 4096)   172.00M\n",
      "model.layers.18.mlp.gate_proj.weight.grad       (11008, 4096)   172.00M\n",
      "model.layers.18.mlp.up_proj.weight             (11008, 4096)   172.00M\n",
      "model.layers.18.mlp.up_proj.weight.grad        (11008, 4096)   172.00M\n",
      "model.layers.18.mlp.down_proj.weight           (4096, 11008)   172.00M\n",
      "model.layers.18.mlp.down_proj.weight.grad       (4096, 11008)   172.00M\n",
      "model.layers.19.self_attn.q_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.19.self_attn.q_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.19.self_attn.k_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.19.self_attn.k_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.19.self_attn.v_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.19.self_attn.v_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.19.self_attn.o_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.19.self_attn.o_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.19.mlp.gate_proj.weight           (11008, 4096)   172.00M\n",
      "model.layers.19.mlp.gate_proj.weight.grad       (11008, 4096)   172.00M\n",
      "model.layers.19.mlp.up_proj.weight             (11008, 4096)   172.00M\n",
      "model.layers.19.mlp.up_proj.weight.grad        (11008, 4096)   172.00M\n",
      "model.layers.19.mlp.down_proj.weight           (4096, 11008)   172.00M\n",
      "model.layers.19.mlp.down_proj.weight.grad       (4096, 11008)   172.00M\n",
      "model.layers.20.self_attn.q_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.20.self_attn.q_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.20.self_attn.k_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.20.self_attn.k_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.20.self_attn.v_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.20.self_attn.v_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.20.self_attn.o_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.20.self_attn.o_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.20.mlp.gate_proj.weight           (11008, 4096)   172.00M\n",
      "model.layers.20.mlp.gate_proj.weight.grad       (11008, 4096)   172.00M\n",
      "model.layers.20.mlp.up_proj.weight             (11008, 4096)   172.00M\n",
      "model.layers.20.mlp.up_proj.weight.grad        (11008, 4096)   172.00M\n",
      "model.layers.20.mlp.down_proj.weight           (4096, 11008)   172.00M\n",
      "model.layers.20.mlp.down_proj.weight.grad       (4096, 11008)   172.00M\n",
      "model.layers.21.self_attn.q_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.21.self_attn.q_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.21.self_attn.k_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.21.self_attn.k_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.21.self_attn.v_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.21.self_attn.v_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.21.self_attn.o_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.21.self_attn.o_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.21.mlp.gate_proj.weight           (11008, 4096)   172.00M\n",
      "model.layers.21.mlp.gate_proj.weight.grad       (11008, 4096)   172.00M\n",
      "model.layers.21.mlp.up_proj.weight             (11008, 4096)   172.00M\n",
      "model.layers.21.mlp.up_proj.weight.grad        (11008, 4096)   172.00M\n",
      "model.layers.21.mlp.down_proj.weight           (4096, 11008)   172.00M\n",
      "model.layers.21.mlp.down_proj.weight.grad       (4096, 11008)   172.00M\n",
      "model.layers.22.self_attn.q_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.22.self_attn.q_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.22.self_attn.k_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.22.self_attn.k_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.22.self_attn.v_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.22.self_attn.v_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.22.self_attn.o_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.22.self_attn.o_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.22.mlp.gate_proj.weight           (11008, 4096)   172.00M\n",
      "model.layers.22.mlp.gate_proj.weight.grad       (11008, 4096)   172.00M\n",
      "model.layers.22.mlp.up_proj.weight             (11008, 4096)   172.00M\n",
      "model.layers.22.mlp.up_proj.weight.grad        (11008, 4096)   172.00M\n",
      "model.layers.22.mlp.down_proj.weight           (4096, 11008)   172.00M\n",
      "model.layers.22.mlp.down_proj.weight.grad       (4096, 11008)   172.00M\n",
      "model.layers.23.self_attn.q_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.23.self_attn.q_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.23.self_attn.k_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.23.self_attn.k_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.23.self_attn.v_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.23.self_attn.v_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.23.self_attn.o_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.23.self_attn.o_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.23.mlp.gate_proj.weight           (11008, 4096)   172.00M\n",
      "model.layers.23.mlp.gate_proj.weight.grad       (11008, 4096)   172.00M\n",
      "model.layers.23.mlp.up_proj.weight             (11008, 4096)   172.00M\n",
      "model.layers.23.mlp.up_proj.weight.grad        (11008, 4096)   172.00M\n",
      "model.layers.23.mlp.down_proj.weight           (4096, 11008)   172.00M\n",
      "model.layers.23.mlp.down_proj.weight.grad       (4096, 11008)   172.00M\n",
      "model.layers.24.self_attn.q_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.24.self_attn.q_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.24.self_attn.k_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.24.self_attn.k_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.24.self_attn.v_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.24.self_attn.v_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.24.self_attn.o_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.24.self_attn.o_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.24.mlp.gate_proj.weight           (11008, 4096)   172.00M\n",
      "model.layers.24.mlp.gate_proj.weight.grad       (11008, 4096)   172.00M\n",
      "model.layers.24.mlp.up_proj.weight             (11008, 4096)   172.00M\n",
      "model.layers.24.mlp.up_proj.weight.grad        (11008, 4096)   172.00M\n",
      "model.layers.24.mlp.down_proj.weight           (4096, 11008)   172.00M\n",
      "model.layers.24.mlp.down_proj.weight.grad       (4096, 11008)   172.00M\n",
      "model.layers.25.self_attn.q_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.25.self_attn.q_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.25.self_attn.k_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.25.self_attn.k_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.25.self_attn.v_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.25.self_attn.v_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.25.self_attn.o_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.25.self_attn.o_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.25.mlp.gate_proj.weight           (11008, 4096)   172.00M\n",
      "model.layers.25.mlp.gate_proj.weight.grad       (11008, 4096)   172.00M\n",
      "model.layers.25.mlp.up_proj.weight             (11008, 4096)   172.00M\n",
      "model.layers.25.mlp.up_proj.weight.grad        (11008, 4096)   172.00M\n",
      "model.layers.25.mlp.down_proj.weight           (4096, 11008)   172.00M\n",
      "model.layers.25.mlp.down_proj.weight.grad       (4096, 11008)   172.00M\n",
      "model.layers.26.self_attn.q_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.26.self_attn.q_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.26.self_attn.k_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.26.self_attn.k_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.26.self_attn.v_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.26.self_attn.v_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.26.self_attn.o_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.26.self_attn.o_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.26.mlp.gate_proj.weight           (11008, 4096)   172.00M\n",
      "model.layers.26.mlp.gate_proj.weight.grad       (11008, 4096)   172.00M\n",
      "model.layers.26.mlp.up_proj.weight             (11008, 4096)   172.00M\n",
      "model.layers.26.mlp.up_proj.weight.grad        (11008, 4096)   172.00M\n",
      "model.layers.26.mlp.down_proj.weight           (4096, 11008)   172.00M\n",
      "model.layers.26.mlp.down_proj.weight.grad       (4096, 11008)   172.00M\n",
      "model.layers.27.self_attn.q_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.27.self_attn.q_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.27.self_attn.k_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.27.self_attn.k_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.27.self_attn.v_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.27.self_attn.v_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.27.self_attn.o_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.27.self_attn.o_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.27.mlp.gate_proj.weight           (11008, 4096)   172.00M\n",
      "model.layers.27.mlp.gate_proj.weight.grad       (11008, 4096)   172.00M\n",
      "model.layers.27.mlp.up_proj.weight             (11008, 4096)   172.00M\n",
      "model.layers.27.mlp.up_proj.weight.grad        (11008, 4096)   172.00M\n",
      "model.layers.27.mlp.down_proj.weight           (4096, 11008)   172.00M\n",
      "model.layers.27.mlp.down_proj.weight.grad       (4096, 11008)   172.00M\n",
      "model.layers.28.self_attn.q_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.28.self_attn.q_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.28.self_attn.k_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.28.self_attn.k_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.28.self_attn.v_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.28.self_attn.v_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.28.self_attn.o_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.28.self_attn.o_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.28.mlp.gate_proj.weight           (11008, 4096)   172.00M\n",
      "model.layers.28.mlp.gate_proj.weight.grad       (11008, 4096)   172.00M\n",
      "model.layers.28.mlp.up_proj.weight             (11008, 4096)   172.00M\n",
      "model.layers.28.mlp.up_proj.weight.grad        (11008, 4096)   172.00M\n",
      "model.layers.28.mlp.down_proj.weight           (4096, 11008)   172.00M\n",
      "model.layers.28.mlp.down_proj.weight.grad       (4096, 11008)   172.00M\n",
      "model.layers.29.self_attn.q_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.29.self_attn.q_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.29.self_attn.k_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.29.self_attn.k_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.29.self_attn.v_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.29.self_attn.v_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.29.self_attn.o_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.29.self_attn.o_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.29.mlp.gate_proj.weight           (11008, 4096)   172.00M\n",
      "model.layers.29.mlp.gate_proj.weight.grad       (11008, 4096)   172.00M\n",
      "model.layers.29.mlp.up_proj.weight             (11008, 4096)   172.00M\n",
      "model.layers.29.mlp.up_proj.weight.grad        (11008, 4096)   172.00M\n",
      "model.layers.29.mlp.down_proj.weight           (4096, 11008)   172.00M\n",
      "model.layers.29.mlp.down_proj.weight.grad       (4096, 11008)   172.00M\n",
      "model.layers.30.self_attn.q_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.30.self_attn.q_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.30.self_attn.k_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.30.self_attn.k_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.30.self_attn.v_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.30.self_attn.v_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.30.self_attn.o_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.30.self_attn.o_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.30.mlp.gate_proj.weight           (11008, 4096)   172.00M\n",
      "model.layers.30.mlp.gate_proj.weight.grad       (11008, 4096)   172.00M\n",
      "model.layers.30.mlp.up_proj.weight             (11008, 4096)   172.00M\n",
      "model.layers.30.mlp.up_proj.weight.grad        (11008, 4096)   172.00M\n",
      "model.layers.30.mlp.down_proj.weight           (4096, 11008)   172.00M\n",
      "model.layers.30.mlp.down_proj.weight.grad       (4096, 11008)   172.00M\n",
      "model.layers.31.self_attn.q_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.31.self_attn.q_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.31.self_attn.k_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.31.self_attn.k_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.31.self_attn.v_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.31.self_attn.v_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.31.self_attn.o_proj.weight         (4096, 4096)    64.00M\n",
      "model.layers.31.self_attn.o_proj.weight.grad        (4096, 4096)    64.00M\n",
      "model.layers.31.mlp.gate_proj.weight           (11008, 4096)   172.00M\n",
      "model.layers.31.mlp.gate_proj.weight.grad       (11008, 4096)   172.00M\n",
      "model.layers.31.mlp.up_proj.weight             (11008, 4096)   172.00M\n",
      "model.layers.31.mlp.up_proj.weight.grad        (11008, 4096)   172.00M\n",
      "model.layers.31.mlp.down_proj.weight           (4096, 11008)   172.00M\n",
      "model.layers.31.mlp.down_proj.weight.grad       (4096, 11008)   172.00M\n",
      "Tensor85                                              (1, 2)   512.00B\n",
      "Tensor86                                              (1, 2)   512.00B\n",
      "Tensor87                                        (1, 2, 4096)    32.00K\n",
      "Tensor88                                        (1, 2, 4096)    32.00K\n",
      "Tensor89                                        (1, 2, 4096)    32.00K\n",
      "Tensor90                                        (1, 2, 4096)    32.00K\n",
      "Tensor91                                        (1, 2, 4096)    32.00K\n",
      "Tensor92                                        (1, 2, 4096)    32.00K\n",
      "Tensor93                                        (1, 2, 4096)    32.00K\n",
      "Tensor94                                        (1, 2, 4096)    32.00K\n",
      "Tensor95                                        (1, 2, 4096)    32.00K\n",
      "Tensor96                                        (1, 2, 4096)    32.00K\n",
      "Tensor97                                        (1, 2, 4096)    32.00K\n",
      "Tensor98                                        (1, 2, 4096)    32.00K\n",
      "Tensor99                                        (1, 2, 4096)    32.00K\n",
      "Tensor100                                       (1, 2, 4096)    32.00K\n",
      "Tensor101                                       (1, 2, 4096)    32.00K\n",
      "Tensor102                                       (1, 2, 4096)    32.00K\n",
      "Tensor103                                       (1, 2, 4096)    32.00K\n",
      "Tensor104                                       (1, 2, 4096)    32.00K\n",
      "Tensor105                                       (1, 2, 4096)    32.00K\n",
      "Tensor106                                       (1, 2, 4096)    32.00K\n",
      "Tensor107                                       (1, 2, 4096)    32.00K\n",
      "Tensor108                                       (1, 2, 4096)    32.00K\n",
      "Tensor109                                       (1, 2, 4096)    32.00K\n",
      "Tensor110                                       (1, 2, 4096)    32.00K\n",
      "Tensor111                                       (1, 2, 4096)    32.00K\n",
      "Tensor112                                       (1, 2, 4096)    32.00K\n",
      "Tensor113                                       (1, 2, 4096)    32.00K\n",
      "Tensor114                                       (1, 2, 4096)    32.00K\n",
      "Tensor115                                       (1, 2, 4096)    32.00K\n",
      "Tensor116                                       (1, 2, 4096)    32.00K\n",
      "Tensor117                                       (1, 2, 4096)    32.00K\n",
      "Tensor118                                       (1, 2, 4096)    32.00K\n",
      "Tensor119                                               (1,)   512.00B\n",
      "Tensor120                                               (1,)   512.00B\n",
      "Tensor121                                               (1,)   512.00B\n",
      "model.layers.30.self_attn.o_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.30.mlp.gate_proj.weight.grad       (11008, 4096)     0.00B\n",
      "model.layers.30.mlp.up_proj.weight.grad        (11008, 4096)     0.00B\n",
      "model.layers.30.mlp.down_proj.weight.grad       (4096, 11008)     0.00B\n",
      "model.layers.30.input_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.layers.30.post_attention_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.layers.31.self_attn.q_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.31.self_attn.k_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.31.self_attn.v_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.31.self_attn.o_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.31.mlp.gate_proj.weight.grad       (11008, 4096)     0.00B\n",
      "model.layers.31.mlp.up_proj.weight.grad        (11008, 4096)     0.00B\n",
      "model.layers.31.mlp.down_proj.weight.grad       (4096, 11008)     0.00B\n",
      "model.layers.31.input_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.layers.31.post_attention_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.norm.weight.grad                               (4096,)     0.00B\n",
      "lm_head.weight.grad                            (32000, 4096)     0.00B\n",
      "Tensor122                                               (1,)   512.00B\n",
      "Tensor123                                      (32000, 4096)   500.00M\n",
      "Tensor124                                      (32000, 4096)   500.00M\n",
      "Tensor125                                               (1,)   512.00B\n",
      "Tensor126                                       (4096, 4096)    64.00M\n",
      "Tensor127                                       (4096, 4096)    64.00M\n",
      "Tensor128                                               (1,)   512.00B\n",
      "Tensor129                                       (4096, 4096)    64.00M\n",
      "Tensor130                                       (4096, 4096)    64.00M\n",
      "Tensor131                                               (1,)   512.00B\n",
      "Tensor132                                       (4096, 4096)    64.00M\n",
      "Tensor133                                       (4096, 4096)    64.00M\n",
      "Tensor134                                               (1,)   512.00B\n",
      "Tensor135                                       (4096, 4096)    64.00M\n",
      "Tensor136                                       (4096, 4096)    64.00M\n",
      "Tensor137                                               (1,)   512.00B\n",
      "Tensor138                                      (11008, 4096)   172.00M\n",
      "Tensor139                                      (11008, 4096)   172.00M\n",
      "Tensor140                                               (1,)   512.00B\n",
      "Tensor141                                      (11008, 4096)   172.00M\n",
      "Tensor142                                      (11008, 4096)   172.00M\n",
      "Tensor143                                               (1,)   512.00B\n",
      "Tensor144                                      (4096, 11008)   172.00M\n",
      "Tensor145                                      (4096, 11008)   172.00M\n",
      "Tensor146                                               (1,)   512.00B\n",
      "Tensor147                                            (4096,)    16.00K\n",
      "Tensor148                                            (4096,)    16.00K\n",
      "Tensor149                                               (1,)   512.00B\n",
      "Tensor150                                            (4096,)    16.00K\n",
      "Tensor151                                            (4096,)    16.00K\n",
      "Tensor152                                               (1,)   512.00B\n",
      "Tensor153                                       (4096, 4096)    64.00M\n",
      "Tensor154                                       (4096, 4096)    64.00M\n",
      "Tensor155                                               (1,)   512.00B\n",
      "Tensor156                                       (4096, 4096)    64.00M\n",
      "Tensor157                                       (4096, 4096)    64.00M\n",
      "Tensor158                                               (1,)   512.00B\n",
      "Tensor159                                       (4096, 4096)    64.00M\n",
      "Tensor160                                       (4096, 4096)    64.00M\n",
      "Tensor161                                               (1,)   512.00B\n",
      "Tensor162                                       (4096, 4096)    64.00M\n",
      "Tensor163                                       (4096, 4096)    64.00M\n",
      "Tensor164                                               (1,)   512.00B\n",
      "Tensor165                                      (11008, 4096)   172.00M\n",
      "Tensor166                                      (11008, 4096)   172.00M\n",
      "Tensor167                                               (1,)   512.00B\n",
      "Tensor168                                      (11008, 4096)   172.00M\n",
      "Tensor169                                      (11008, 4096)   172.00M\n",
      "Tensor170                                               (1,)   512.00B\n",
      "Tensor171                                      (4096, 11008)   172.00M\n",
      "Tensor172                                      (4096, 11008)   172.00M\n",
      "Tensor173                                               (1,)   512.00B\n",
      "Tensor174                                            (4096,)    16.00K\n",
      "Tensor175                                            (4096,)    16.00K\n",
      "Tensor176                                               (1,)   512.00B\n",
      "Tensor177                                            (4096,)    16.00K\n",
      "Tensor178                                            (4096,)    16.00K\n",
      "Tensor179                                               (1,)   512.00B\n",
      "Tensor180                                       (4096, 4096)    64.00M\n",
      "Tensor181                                       (4096, 4096)    64.00M\n",
      "Tensor182                                               (1,)   512.00B\n",
      "Tensor183                                       (4096, 4096)    64.00M\n",
      "Tensor184                                       (4096, 4096)    64.00M\n",
      "Tensor185                                               (1,)   512.00B\n",
      "Tensor186                                       (4096, 4096)    64.00M\n",
      "Tensor187                                       (4096, 4096)    64.00M\n",
      "Tensor188                                               (1,)   512.00B\n",
      "Tensor189                                       (4096, 4096)    64.00M\n",
      "Tensor190                                       (4096, 4096)    64.00M\n",
      "Tensor191                                               (1,)   512.00B\n",
      "Tensor192                                      (11008, 4096)   172.00M\n",
      "Tensor193                                      (11008, 4096)   172.00M\n",
      "Tensor194                                               (1,)   512.00B\n",
      "Tensor195                                      (11008, 4096)   172.00M\n",
      "Tensor196                                      (11008, 4096)   172.00M\n",
      "Tensor197                                               (1,)   512.00B\n",
      "Tensor198                                      (4096, 11008)   172.00M\n",
      "Tensor199                                      (4096, 11008)   172.00M\n",
      "Tensor200                                               (1,)   512.00B\n",
      "Tensor201                                            (4096,)    16.00K\n",
      "Tensor202                                            (4096,)    16.00K\n",
      "Tensor203                                               (1,)   512.00B\n",
      "Tensor204                                            (4096,)    16.00K\n",
      "Tensor205                                            (4096,)    16.00K\n",
      "Tensor206                                               (1,)   512.00B\n",
      "Tensor207                                       (4096, 4096)    64.00M\n",
      "Tensor208                                       (4096, 4096)    64.00M\n",
      "Tensor209                                               (1,)   512.00B\n",
      "Tensor210                                       (4096, 4096)    64.00M\n",
      "Tensor211                                       (4096, 4096)    64.00M\n",
      "Tensor212                                               (1,)   512.00B\n",
      "Tensor213                                       (4096, 4096)    64.00M\n",
      "Tensor214                                       (4096, 4096)    64.00M\n",
      "Tensor215                                               (1,)   512.00B\n",
      "Tensor216                                       (4096, 4096)    64.00M\n",
      "Tensor217                                       (4096, 4096)    64.00M\n",
      "Tensor218                                               (1,)   512.00B\n",
      "Tensor219                                      (11008, 4096)   172.00M\n",
      "Tensor220                                      (11008, 4096)   172.00M\n",
      "Tensor221                                               (1,)   512.00B\n",
      "Tensor222                                      (11008, 4096)   172.00M\n",
      "Tensor223                                      (11008, 4096)   172.00M\n",
      "Tensor224                                               (1,)   512.00B\n",
      "Tensor225                                      (4096, 11008)   172.00M\n",
      "Tensor226                                      (4096, 11008)   172.00M\n",
      "Tensor227                                               (1,)   512.00B\n",
      "Tensor228                                            (4096,)    16.00K\n",
      "Tensor229                                            (4096,)    16.00K\n",
      "Tensor230                                               (1,)   512.00B\n",
      "Tensor231                                            (4096,)    16.00K\n",
      "Tensor232                                            (4096,)    16.00K\n",
      "Tensor233                                               (1,)   512.00B\n",
      "Tensor234                                       (4096, 4096)    64.00M\n",
      "Tensor235                                       (4096, 4096)    64.00M\n",
      "Tensor236                                               (1,)   512.00B\n",
      "Tensor237                                       (4096, 4096)    64.00M\n",
      "Tensor238                                       (4096, 4096)    64.00M\n",
      "Tensor239                                               (1,)   512.00B\n",
      "Tensor240                                       (4096, 4096)    64.00M\n",
      "Tensor241                                       (4096, 4096)    64.00M\n",
      "Tensor242                                               (1,)   512.00B\n",
      "Tensor243                                       (4096, 4096)    64.00M\n",
      "Tensor244                                       (4096, 4096)    64.00M\n",
      "Tensor245                                               (1,)   512.00B\n",
      "Tensor246                                      (11008, 4096)   172.00M\n",
      "Tensor247                                      (11008, 4096)   172.00M\n",
      "Tensor248                                               (1,)   512.00B\n",
      "Tensor249                                      (11008, 4096)   172.00M\n",
      "Tensor250                                      (11008, 4096)   172.00M\n",
      "Tensor251                                               (1,)   512.00B\n",
      "Tensor252                                      (4096, 11008)   172.00M\n",
      "Tensor253                                      (4096, 11008)   172.00M\n",
      "Tensor254                                               (1,)   512.00B\n",
      "Tensor255                                            (4096,)    16.00K\n",
      "Tensor256                                            (4096,)    16.00K\n",
      "Tensor257                                               (1,)   512.00B\n",
      "Tensor258                                            (4096,)    16.00K\n",
      "Tensor259                                            (4096,)    16.00K\n",
      "Tensor260                                               (1,)   512.00B\n",
      "Tensor261                                       (4096, 4096)    64.00M\n",
      "Tensor262                                       (4096, 4096)    64.00M\n",
      "Tensor263                                               (1,)   512.00B\n",
      "Tensor264                                       (4096, 4096)    64.00M\n",
      "Tensor265                                       (4096, 4096)    64.00M\n",
      "Tensor266                                               (1,)   512.00B\n",
      "Tensor267                                       (4096, 4096)    64.00M\n",
      "Tensor268                                       (4096, 4096)    64.00M\n",
      "Tensor269                                               (1,)   512.00B\n",
      "Tensor270                                       (4096, 4096)    64.00M\n",
      "Tensor271                                       (4096, 4096)    64.00M\n",
      "Tensor272                                               (1,)   512.00B\n",
      "Tensor273                                      (11008, 4096)   172.00M\n",
      "Tensor274                                      (11008, 4096)   172.00M\n",
      "Tensor275                                               (1,)   512.00B\n",
      "Tensor276                                      (11008, 4096)   172.00M\n",
      "Tensor277                                      (11008, 4096)   172.00M\n",
      "Tensor278                                               (1,)   512.00B\n",
      "Tensor279                                      (4096, 11008)   172.00M\n",
      "Tensor280                                      (4096, 11008)   172.00M\n",
      "Tensor281                                               (1,)   512.00B\n",
      "Tensor282                                            (4096,)    16.00K\n",
      "Tensor283                                            (4096,)    16.00K\n",
      "Tensor284                                               (1,)   512.00B\n",
      "Tensor285                                            (4096,)    16.00K\n",
      "Tensor286                                            (4096,)    16.00K\n",
      "Tensor287                                               (1,)   512.00B\n",
      "Tensor288                                       (4096, 4096)    64.00M\n",
      "Tensor289                                       (4096, 4096)    64.00M\n",
      "Tensor290                                               (1,)   512.00B\n",
      "Tensor291                                       (4096, 4096)    64.00M\n",
      "Tensor292                                       (4096, 4096)    64.00M\n",
      "Tensor293                                               (1,)   512.00B\n",
      "Tensor294                                       (4096, 4096)    64.00M\n",
      "Tensor295                                       (4096, 4096)    64.00M\n",
      "Tensor296                                               (1,)   512.00B\n",
      "Tensor297                                       (4096, 4096)    64.00M\n",
      "Tensor298                                       (4096, 4096)    64.00M\n",
      "Tensor299                                               (1,)   512.00B\n",
      "Tensor300                                      (11008, 4096)   172.00M\n",
      "Tensor301                                      (11008, 4096)   172.00M\n",
      "Tensor302                                               (1,)   512.00B\n",
      "Tensor303                                      (11008, 4096)   172.00M\n",
      "Tensor304                                      (11008, 4096)   172.00M\n",
      "Tensor305                                               (1,)   512.00B\n",
      "Tensor306                                      (4096, 11008)   172.00M\n",
      "Tensor307                                      (4096, 11008)   172.00M\n",
      "Tensor308                                               (1,)   512.00B\n",
      "Tensor309                                            (4096,)    16.00K\n",
      "Tensor310                                            (4096,)    16.00K\n",
      "Tensor311                                               (1,)   512.00B\n",
      "Tensor312                                            (4096,)    16.00K\n",
      "Tensor313                                            (4096,)    16.00K\n",
      "Tensor314                                               (1,)   512.00B\n",
      "Tensor315                                       (4096, 4096)    64.00M\n",
      "Tensor316                                       (4096, 4096)    64.00M\n",
      "Tensor317                                               (1,)   512.00B\n",
      "Tensor318                                       (4096, 4096)    64.00M\n",
      "Tensor319                                       (4096, 4096)    64.00M\n",
      "Tensor320                                               (1,)   512.00B\n",
      "Tensor321                                       (4096, 4096)    64.00M\n",
      "Tensor322                                       (4096, 4096)    64.00M\n",
      "Tensor323                                               (1,)   512.00B\n",
      "Tensor324                                       (4096, 4096)    64.00M\n",
      "Tensor325                                       (4096, 4096)    64.00M\n",
      "Tensor326                                               (1,)   512.00B\n",
      "Tensor327                                      (11008, 4096)   172.00M\n",
      "Tensor328                                      (11008, 4096)   172.00M\n",
      "Tensor329                                               (1,)   512.00B\n",
      "Tensor330                                      (11008, 4096)   172.00M\n",
      "Tensor331                                      (11008, 4096)   172.00M\n",
      "Tensor332                                               (1,)   512.00B\n",
      "Tensor333                                      (4096, 11008)   172.00M\n",
      "Tensor334                                      (4096, 11008)   172.00M\n",
      "Tensor335                                               (1,)   512.00B\n",
      "Tensor336                                            (4096,)    16.00K\n",
      "Tensor337                                            (4096,)    16.00K\n",
      "Tensor338                                               (1,)   512.00B\n",
      "Tensor339                                            (4096,)    16.00K\n",
      "Tensor340                                            (4096,)    16.00K\n",
      "Tensor341                                               (1,)   512.00B\n",
      "Tensor342                                       (4096, 4096)    64.00M\n",
      "Tensor343                                       (4096, 4096)    64.00M\n",
      "Tensor344                                               (1,)   512.00B\n",
      "Tensor345                                       (4096, 4096)    64.00M\n",
      "Tensor346                                       (4096, 4096)    64.00M\n",
      "Tensor347                                               (1,)   512.00B\n",
      "Tensor348                                       (4096, 4096)    64.00M\n",
      "Tensor349                                       (4096, 4096)    64.00M\n",
      "Tensor350                                               (1,)   512.00B\n",
      "Tensor351                                       (4096, 4096)    64.00M\n",
      "Tensor352                                       (4096, 4096)    64.00M\n",
      "Tensor353                                               (1,)   512.00B\n",
      "Tensor354                                      (11008, 4096)   172.00M\n",
      "Tensor355                                      (11008, 4096)   172.00M\n",
      "Tensor356                                               (1,)   512.00B\n",
      "Tensor357                                      (11008, 4096)   172.00M\n",
      "Tensor358                                      (11008, 4096)   172.00M\n",
      "Tensor359                                               (1,)   512.00B\n",
      "Tensor360                                      (4096, 11008)   172.00M\n",
      "Tensor361                                      (4096, 11008)   172.00M\n",
      "Tensor362                                               (1,)   512.00B\n",
      "Tensor363                                            (4096,)    16.00K\n",
      "Tensor364                                            (4096,)    16.00K\n",
      "Tensor365                                               (1,)   512.00B\n",
      "Tensor366                                            (4096,)    16.00K\n",
      "Tensor367                                            (4096,)    16.00K\n",
      "Tensor368                                               (1,)   512.00B\n",
      "Tensor369                                       (4096, 4096)    64.00M\n",
      "Tensor370                                       (4096, 4096)    64.00M\n",
      "Tensor371                                               (1,)   512.00B\n",
      "Tensor372                                       (4096, 4096)    64.00M\n",
      "Tensor373                                       (4096, 4096)    64.00M\n",
      "Tensor374                                               (1,)   512.00B\n",
      "Tensor375                                       (4096, 4096)    64.00M\n",
      "Tensor376                                       (4096, 4096)    64.00M\n",
      "Tensor377                                               (1,)   512.00B\n",
      "Tensor378                                       (4096, 4096)    64.00M\n",
      "Tensor379                                       (4096, 4096)    64.00M\n",
      "Tensor380                                               (1,)   512.00B\n",
      "Tensor381                                      (11008, 4096)   172.00M\n",
      "Tensor382                                      (11008, 4096)   172.00M\n",
      "Tensor383                                               (1,)   512.00B\n",
      "Tensor384                                      (11008, 4096)   172.00M\n",
      "Tensor385                                      (11008, 4096)   172.00M\n",
      "Tensor386                                               (1,)   512.00B\n",
      "Tensor387                                      (4096, 11008)   172.00M\n",
      "Tensor388                                      (4096, 11008)   172.00M\n",
      "Tensor389                                               (1,)   512.00B\n",
      "Tensor390                                            (4096,)    16.00K\n",
      "Tensor391                                            (4096,)    16.00K\n",
      "Tensor392                                               (1,)   512.00B\n",
      "Tensor393                                            (4096,)    16.00K\n",
      "Tensor394                                            (4096,)    16.00K\n",
      "Tensor395                                               (1,)   512.00B\n",
      "Tensor396                                       (4096, 4096)    64.00M\n",
      "Tensor397                                       (4096, 4096)    64.00M\n",
      "Tensor398                                               (1,)   512.00B\n",
      "Tensor399                                       (4096, 4096)    64.00M\n",
      "Tensor400                                       (4096, 4096)    64.00M\n",
      "Tensor401                                               (1,)   512.00B\n",
      "Tensor402                                       (4096, 4096)    64.00M\n",
      "Tensor403                                       (4096, 4096)    64.00M\n",
      "Tensor404                                               (1,)   512.00B\n",
      "Tensor405                                       (4096, 4096)    64.00M\n",
      "Tensor406                                       (4096, 4096)    64.00M\n",
      "Tensor407                                               (1,)   512.00B\n",
      "Tensor408                                      (11008, 4096)   172.00M\n",
      "Tensor409                                      (11008, 4096)   172.00M\n",
      "Tensor410                                               (1,)   512.00B\n",
      "Tensor411                                      (11008, 4096)   172.00M\n",
      "Tensor412                                      (11008, 4096)   172.00M\n",
      "Tensor413                                               (1,)   512.00B\n",
      "Tensor414                                      (4096, 11008)   172.00M\n",
      "Tensor415                                      (4096, 11008)   172.00M\n",
      "Tensor416                                            (4096,)    16.00K\n",
      "Tensor417                                      (1, 2, 32000)   250.00K\n",
      "model.layers.10.input_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.layers.10.mlp.down_proj.weight.grad       (4096, 11008)     0.00B\n",
      "model.layers.10.mlp.up_proj.weight.grad        (11008, 4096)     0.00B\n",
      "model.layers.10.mlp.gate_proj.weight.grad       (11008, 4096)     0.00B\n",
      "model.layers.10.self_attn.o_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.10.self_attn.v_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.10.self_attn.k_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.10.self_attn.q_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.9.post_attention_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.layers.9.input_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.layers.9.mlp.down_proj.weight.grad       (4096, 11008)     0.00B\n",
      "model.layers.9.mlp.up_proj.weight.grad         (11008, 4096)     0.00B\n",
      "model.layers.9.mlp.gate_proj.weight.grad       (11008, 4096)     0.00B\n",
      "model.layers.9.self_attn.o_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.9.self_attn.v_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.9.self_attn.k_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.9.self_attn.q_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.8.post_attention_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.layers.8.input_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.layers.8.mlp.down_proj.weight.grad       (4096, 11008)     0.00B\n",
      "model.layers.8.mlp.up_proj.weight.grad         (11008, 4096)     0.00B\n",
      "model.layers.8.mlp.gate_proj.weight.grad       (11008, 4096)     0.00B\n",
      "model.layers.8.self_attn.o_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.8.self_attn.v_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.8.self_attn.k_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.8.self_attn.q_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.7.post_attention_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.layers.7.input_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.layers.7.mlp.down_proj.weight.grad       (4096, 11008)     0.00B\n",
      "model.layers.7.mlp.up_proj.weight.grad         (11008, 4096)     0.00B\n",
      "model.layers.7.mlp.gate_proj.weight.grad       (11008, 4096)     0.00B\n",
      "model.layers.7.self_attn.o_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.7.self_attn.v_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.7.self_attn.k_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.7.self_attn.q_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.6.post_attention_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.layers.6.input_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.layers.6.mlp.down_proj.weight.grad       (4096, 11008)     0.00B\n",
      "model.layers.6.mlp.up_proj.weight.grad         (11008, 4096)     0.00B\n",
      "model.layers.6.mlp.gate_proj.weight.grad       (11008, 4096)     0.00B\n",
      "model.layers.6.self_attn.o_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.6.self_attn.v_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.6.self_attn.k_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.6.self_attn.q_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.5.post_attention_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.layers.5.input_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.layers.5.mlp.down_proj.weight.grad       (4096, 11008)     0.00B\n",
      "model.layers.5.mlp.up_proj.weight.grad         (11008, 4096)     0.00B\n",
      "model.layers.5.mlp.gate_proj.weight.grad       (11008, 4096)     0.00B\n",
      "model.layers.5.self_attn.o_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.5.self_attn.v_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.5.self_attn.k_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.5.self_attn.q_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.4.post_attention_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.layers.4.input_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.layers.4.mlp.down_proj.weight.grad       (4096, 11008)     0.00B\n",
      "model.layers.4.mlp.up_proj.weight.grad         (11008, 4096)     0.00B\n",
      "model.layers.4.mlp.gate_proj.weight.grad       (11008, 4096)     0.00B\n",
      "model.layers.4.self_attn.o_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.4.self_attn.v_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.4.self_attn.k_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.4.self_attn.q_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.3.post_attention_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.layers.3.input_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.layers.3.mlp.down_proj.weight.grad       (4096, 11008)     0.00B\n",
      "model.layers.3.mlp.up_proj.weight.grad         (11008, 4096)     0.00B\n",
      "model.layers.3.mlp.gate_proj.weight.grad       (11008, 4096)     0.00B\n",
      "model.layers.3.self_attn.o_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.3.self_attn.v_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.3.self_attn.k_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.3.self_attn.q_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.2.post_attention_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.layers.2.input_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.layers.2.mlp.down_proj.weight.grad       (4096, 11008)     0.00B\n",
      "model.layers.2.mlp.up_proj.weight.grad         (11008, 4096)     0.00B\n",
      "model.layers.2.mlp.gate_proj.weight.grad       (11008, 4096)     0.00B\n",
      "model.layers.2.self_attn.o_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.2.self_attn.v_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.2.self_attn.k_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.2.self_attn.q_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.1.post_attention_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.layers.1.input_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.layers.1.mlp.down_proj.weight.grad       (4096, 11008)     0.00B\n",
      "model.layers.1.mlp.up_proj.weight.grad         (11008, 4096)     0.00B\n",
      "model.layers.1.mlp.gate_proj.weight.grad       (11008, 4096)     0.00B\n",
      "model.layers.1.self_attn.o_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.1.self_attn.v_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.1.self_attn.k_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.1.self_attn.q_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.0.post_attention_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.layers.0.input_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.layers.0.mlp.down_proj.weight.grad       (4096, 11008)     0.00B\n",
      "model.layers.0.mlp.up_proj.weight.grad         (11008, 4096)     0.00B\n",
      "model.layers.0.mlp.gate_proj.weight.grad       (11008, 4096)     0.00B\n",
      "model.layers.0.self_attn.o_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.0.self_attn.v_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.0.self_attn.k_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.0.self_attn.q_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.embed_tokens.weight.grad                 (32000, 4096)     0.00B\n",
      "Tensor418                                               (1,)   512.00B\n",
      "Tensor419                                    (1, 32, 2, 128)     0.00B\n",
      "Tensor420                                    (1, 32, 2, 128)    32.00K\n",
      "Tensor421                                            (4096,)    16.00K\n",
      "Tensor422                                               (1,)   512.00B\n",
      "Tensor423                                            (4096,)    16.00K\n",
      "Tensor424                                            (4096,)    16.00K\n",
      "Tensor425                                               (1,)   512.00B\n",
      "Tensor426                                       (4096, 4096)    64.00M\n",
      "Tensor427                                       (4096, 4096)    64.00M\n",
      "Tensor428                                               (1,)   512.00B\n",
      "Tensor429                                       (4096, 4096)    64.00M\n",
      "Tensor430                                       (4096, 4096)    64.00M\n",
      "Tensor431                                               (1,)   512.00B\n",
      "Tensor432                                       (4096, 4096)    64.00M\n",
      "Tensor433                                       (4096, 4096)    64.00M\n",
      "Tensor434                                               (1,)   512.00B\n",
      "Tensor435                                       (4096, 4096)    64.00M\n",
      "Tensor436                                       (4096, 4096)    64.00M\n",
      "Tensor437                                               (1,)   512.00B\n",
      "Tensor438                                      (11008, 4096)   172.00M\n",
      "Tensor439                                      (11008, 4096)   172.00M\n",
      "Tensor440                                               (1,)   512.00B\n",
      "Tensor441                                      (11008, 4096)   172.00M\n",
      "Tensor442                                      (11008, 4096)   172.00M\n",
      "Tensor443                                               (1,)   512.00B\n",
      "Tensor444                                      (4096, 11008)   172.00M\n",
      "Tensor445                                      (4096, 11008)   172.00M\n",
      "Tensor446                                               (1,)   512.00B\n",
      "Tensor447                                            (4096,)    16.00K\n",
      "Tensor448                                            (4096,)    16.00K\n",
      "Tensor449                                               (1,)   512.00B\n",
      "Tensor450                                            (4096,)    16.00K\n",
      "Tensor451                                            (4096,)    16.00K\n",
      "Tensor452                                               (1,)   512.00B\n",
      "Tensor453                                       (4096, 4096)    64.00M\n",
      "Tensor454                                       (4096, 4096)    64.00M\n",
      "Tensor455                                               (1,)   512.00B\n",
      "Tensor456                                       (4096, 4096)    64.00M\n",
      "Tensor457                                       (4096, 4096)    64.00M\n",
      "Tensor458                                               (1,)   512.00B\n",
      "Tensor459                                       (4096, 4096)    64.00M\n",
      "Tensor460                                       (4096, 4096)    64.00M\n",
      "Tensor461                                               (1,)   512.00B\n",
      "Tensor462                                       (4096, 4096)    64.00M\n",
      "Tensor463                                       (4096, 4096)    64.00M\n",
      "Tensor464                                               (1,)   512.00B\n",
      "Tensor465                                      (11008, 4096)   172.00M\n",
      "Tensor466                                      (11008, 4096)   172.00M\n",
      "Tensor467                                               (1,)   512.00B\n",
      "Tensor468                                      (11008, 4096)   172.00M\n",
      "Tensor469                                      (11008, 4096)   172.00M\n",
      "Tensor470                                               (1,)   512.00B\n",
      "Tensor471                                      (4096, 11008)   172.00M\n",
      "Tensor472                                      (4096, 11008)   172.00M\n",
      "Tensor473                                               (1,)   512.00B\n",
      "Tensor474                                            (4096,)    16.00K\n",
      "Tensor475                                            (4096,)    16.00K\n",
      "Tensor476                                               (1,)   512.00B\n",
      "Tensor477                                            (4096,)    16.00K\n",
      "Tensor478                                            (4096,)    16.00K\n",
      "Tensor479                                               (1,)   512.00B\n",
      "Tensor480                                       (4096, 4096)    64.00M\n",
      "Tensor481                                       (4096, 4096)    64.00M\n",
      "Tensor482                                               (1,)   512.00B\n",
      "Tensor483                                       (4096, 4096)    64.00M\n",
      "Tensor484                                       (4096, 4096)    64.00M\n",
      "Tensor485                                               (1,)   512.00B\n",
      "Tensor486                                       (4096, 4096)    64.00M\n",
      "Tensor487                                       (4096, 4096)    64.00M\n",
      "Tensor488                                               (1,)   512.00B\n",
      "Tensor489                                       (4096, 4096)    64.00M\n",
      "Tensor490                                       (4096, 4096)    64.00M\n",
      "Tensor491                                               (1,)   512.00B\n",
      "Tensor492                                      (11008, 4096)   172.00M\n",
      "Tensor493                                      (11008, 4096)   172.00M\n",
      "Tensor494                                               (1,)   512.00B\n",
      "Tensor495                                      (11008, 4096)   172.00M\n",
      "Tensor496                                      (11008, 4096)   172.00M\n",
      "Tensor497                                               (1,)   512.00B\n",
      "Tensor498                                      (4096, 11008)   172.00M\n",
      "Tensor499                                      (4096, 11008)   172.00M\n",
      "Tensor500                                               (1,)   512.00B\n",
      "Tensor501                                            (4096,)    16.00K\n",
      "Tensor502                                            (4096,)    16.00K\n",
      "Tensor503                                               (1,)   512.00B\n",
      "Tensor504                                            (4096,)    16.00K\n",
      "Tensor505                                            (4096,)    16.00K\n",
      "Tensor506                                               (1,)   512.00B\n",
      "Tensor507                                       (4096, 4096)    64.00M\n",
      "Tensor508                                       (4096, 4096)    64.00M\n",
      "Tensor509                                               (1,)   512.00B\n",
      "Tensor510                                       (4096, 4096)    64.00M\n",
      "Tensor511                                       (4096, 4096)    64.00M\n",
      "Tensor512                                               (1,)   512.00B\n",
      "Tensor513                                       (4096, 4096)    64.00M\n",
      "Tensor514                                       (4096, 4096)    64.00M\n",
      "Tensor515                                               (1,)   512.00B\n",
      "Tensor516                                       (4096, 4096)    64.00M\n",
      "Tensor517                                       (4096, 4096)    64.00M\n",
      "Tensor518                                               (1,)   512.00B\n",
      "Tensor519                                      (11008, 4096)   172.00M\n",
      "Tensor520                                      (11008, 4096)   172.00M\n",
      "Tensor521                                               (1,)   512.00B\n",
      "Tensor522                                      (11008, 4096)   172.00M\n",
      "Tensor523                                      (11008, 4096)   172.00M\n",
      "Tensor524                                               (1,)   512.00B\n",
      "Tensor525                                      (4096, 11008)   172.00M\n",
      "Tensor526                                      (4096, 11008)   172.00M\n",
      "Tensor527                                               (1,)   512.00B\n",
      "Tensor528                                            (4096,)    16.00K\n",
      "Tensor529                                            (4096,)    16.00K\n",
      "Tensor530                                               (1,)   512.00B\n",
      "Tensor531                                            (4096,)    16.00K\n",
      "Tensor532                                            (4096,)    16.00K\n",
      "Tensor533                                               (1,)   512.00B\n",
      "Tensor534                                       (4096, 4096)    64.00M\n",
      "Tensor535                                       (4096, 4096)    64.00M\n",
      "Tensor536                                               (1,)   512.00B\n",
      "Tensor537                                       (4096, 4096)    64.00M\n",
      "Tensor538                                       (4096, 4096)    64.00M\n",
      "Tensor539                                               (1,)   512.00B\n",
      "Tensor540                                       (4096, 4096)    64.00M\n",
      "Tensor541                                       (4096, 4096)    64.00M\n",
      "Tensor542                                               (1,)   512.00B\n",
      "Tensor543                                       (4096, 4096)    64.00M\n",
      "Tensor544                                       (4096, 4096)    64.00M\n",
      "Tensor545                                               (1,)   512.00B\n",
      "Tensor546                                      (11008, 4096)   172.00M\n",
      "Tensor547                                      (11008, 4096)   172.00M\n",
      "Tensor548                                               (1,)   512.00B\n",
      "Tensor549                                      (11008, 4096)   172.00M\n",
      "Tensor550                                      (11008, 4096)   172.00M\n",
      "Tensor551                                               (1,)   512.00B\n",
      "Tensor552                                      (4096, 11008)   172.00M\n",
      "Tensor553                                      (4096, 11008)   172.00M\n",
      "Tensor554                                               (1,)   512.00B\n",
      "Tensor555                                            (4096,)    16.00K\n",
      "Tensor556                                            (4096,)    16.00K\n",
      "Tensor557                                               (1,)   512.00B\n",
      "Tensor558                                            (4096,)    16.00K\n",
      "Tensor559                                            (4096,)    16.00K\n",
      "Tensor560                                               (1,)   512.00B\n",
      "Tensor561                                       (4096, 4096)    64.00M\n",
      "Tensor562                                       (4096, 4096)    64.00M\n",
      "Tensor563                                               (1,)   512.00B\n",
      "Tensor564                                       (4096, 4096)    64.00M\n",
      "Tensor565                                       (4096, 4096)    64.00M\n",
      "Tensor566                                               (1,)   512.00B\n",
      "Tensor567                                       (4096, 4096)    64.00M\n",
      "Tensor568                                       (4096, 4096)    64.00M\n",
      "Tensor569                                               (1,)   512.00B\n",
      "Tensor570                                       (4096, 4096)    64.00M\n",
      "Tensor571                                       (4096, 4096)    64.00M\n",
      "Tensor572                                               (1,)   512.00B\n",
      "Tensor573                                      (11008, 4096)   172.00M\n",
      "Tensor574                                      (11008, 4096)   172.00M\n",
      "Tensor575                                               (1,)   512.00B\n",
      "Tensor576                                      (11008, 4096)   172.00M\n",
      "Tensor577                                      (11008, 4096)   172.00M\n",
      "Tensor578                                               (1,)   512.00B\n",
      "Tensor579                                      (4096, 11008)   172.00M\n",
      "Tensor580                                      (4096, 11008)   172.00M\n",
      "Tensor581                                               (1,)   512.00B\n",
      "Tensor582                                            (4096,)    16.00K\n",
      "Tensor583                                            (4096,)    16.00K\n",
      "Tensor584                                               (1,)   512.00B\n",
      "Tensor585                                            (4096,)    16.00K\n",
      "Tensor586                                            (4096,)    16.00K\n",
      "Tensor587                                               (1,)   512.00B\n",
      "Tensor588                                       (4096, 4096)    64.00M\n",
      "Tensor589                                       (4096, 4096)    64.00M\n",
      "Tensor590                                               (1,)   512.00B\n",
      "Tensor591                                       (4096, 4096)    64.00M\n",
      "Tensor592                                       (4096, 4096)    64.00M\n",
      "Tensor593                                               (1,)   512.00B\n",
      "Tensor594                                       (4096, 4096)    64.00M\n",
      "Tensor595                                       (4096, 4096)    64.00M\n",
      "Tensor596                                               (1,)   512.00B\n",
      "Tensor597                                       (4096, 4096)    64.00M\n",
      "Tensor598                                       (4096, 4096)    64.00M\n",
      "Tensor599                                               (1,)   512.00B\n",
      "Tensor600                                      (11008, 4096)   172.00M\n",
      "Tensor601                                      (11008, 4096)   172.00M\n",
      "Tensor602                                               (1,)   512.00B\n",
      "Tensor603                                      (11008, 4096)   172.00M\n",
      "Tensor604                                      (11008, 4096)   172.00M\n",
      "Tensor605                                               (1,)   512.00B\n",
      "Tensor606                                      (4096, 11008)   172.00M\n",
      "Tensor607                                      (4096, 11008)   172.00M\n",
      "Tensor608                                               (1,)   512.00B\n",
      "Tensor609                                            (4096,)    16.00K\n",
      "Tensor610                                            (4096,)    16.00K\n",
      "Tensor611                                               (1,)   512.00B\n",
      "Tensor612                                            (4096,)    16.00K\n",
      "Tensor613                                            (4096,)    16.00K\n",
      "Tensor614                                               (1,)   512.00B\n",
      "Tensor615                                       (4096, 4096)    64.00M\n",
      "Tensor616                                       (4096, 4096)    64.00M\n",
      "Tensor617                                               (1,)   512.00B\n",
      "Tensor618                                       (4096, 4096)    64.00M\n",
      "Tensor619                                       (4096, 4096)    64.00M\n",
      "Tensor620                                               (1,)   512.00B\n",
      "Tensor621                                       (4096, 4096)    64.00M\n",
      "Tensor622                                       (4096, 4096)    64.00M\n",
      "Tensor623                                               (1,)   512.00B\n",
      "Tensor624                                       (4096, 4096)    64.00M\n",
      "Tensor625                                       (4096, 4096)    64.00M\n",
      "Tensor626                                               (1,)   512.00B\n",
      "Tensor627                                      (11008, 4096)   172.00M\n",
      "Tensor628                                      (11008, 4096)   172.00M\n",
      "Tensor629                                               (1,)   512.00B\n",
      "Tensor630                                      (11008, 4096)   172.00M\n",
      "Tensor631                                      (11008, 4096)   172.00M\n",
      "Tensor632                                               (1,)   512.00B\n",
      "Tensor633                                      (4096, 11008)   172.00M\n",
      "Tensor634                                      (4096, 11008)   172.00M\n",
      "Tensor635                                               (1,)   512.00B\n",
      "Tensor636                                            (4096,)    16.00K\n",
      "Tensor637                                            (4096,)    16.00K\n",
      "Tensor638                                               (1,)   512.00B\n",
      "Tensor639                                            (4096,)    16.00K\n",
      "Tensor640                                            (4096,)    16.00K\n",
      "Tensor641                                               (1,)   512.00B\n",
      "Tensor642                                       (4096, 4096)    64.00M\n",
      "Tensor643                                       (4096, 4096)    64.00M\n",
      "Tensor644                                               (1,)   512.00B\n",
      "Tensor645                                       (4096, 4096)    64.00M\n",
      "Tensor646                                       (4096, 4096)    64.00M\n",
      "Tensor647                                               (1,)   512.00B\n",
      "Tensor648                                       (4096, 4096)    64.00M\n",
      "Tensor649                                       (4096, 4096)    64.00M\n",
      "Tensor650                                               (1,)   512.00B\n",
      "Tensor651                                       (4096, 4096)    64.00M\n",
      "Tensor652                                       (4096, 4096)    64.00M\n",
      "Tensor653                                               (1,)   512.00B\n",
      "Tensor654                                      (11008, 4096)   172.00M\n",
      "Tensor655                                      (11008, 4096)   172.00M\n",
      "Tensor656                                               (1,)   512.00B\n",
      "Tensor657                                      (11008, 4096)   172.00M\n",
      "Tensor658                                      (11008, 4096)   172.00M\n",
      "Tensor659                                               (1,)   512.00B\n",
      "Tensor660                                      (4096, 11008)   172.00M\n",
      "Tensor661                                      (4096, 11008)   172.00M\n",
      "Tensor662                                               (1,)   512.00B\n",
      "Tensor663                                            (4096,)    16.00K\n",
      "Tensor664                                            (4096,)    16.00K\n",
      "Tensor665                                               (1,)   512.00B\n",
      "Tensor666                                            (4096,)    16.00K\n",
      "Tensor667                                            (4096,)    16.00K\n",
      "Tensor668                                               (1,)   512.00B\n",
      "Tensor669                                       (4096, 4096)    64.00M\n",
      "Tensor670                                       (4096, 4096)    64.00M\n",
      "Tensor671                                               (1,)   512.00B\n",
      "Tensor672                                       (4096, 4096)    64.00M\n",
      "Tensor673                                       (4096, 4096)    64.00M\n",
      "Tensor674                                               (1,)   512.00B\n",
      "Tensor675                                       (4096, 4096)    64.00M\n",
      "Tensor676                                       (4096, 4096)    64.00M\n",
      "Tensor677                                               (1,)   512.00B\n",
      "Tensor678                                       (4096, 4096)    64.00M\n",
      "Tensor679                                       (4096, 4096)    64.00M\n",
      "Tensor680                                               (1,)   512.00B\n",
      "Tensor681                                      (11008, 4096)   172.00M\n",
      "Tensor682                                      (11008, 4096)   172.00M\n",
      "Tensor683                                               (1,)   512.00B\n",
      "Tensor684                                      (11008, 4096)   172.00M\n",
      "Tensor685                                      (11008, 4096)   172.00M\n",
      "Tensor686                                               (1,)   512.00B\n",
      "Tensor687                                      (4096, 11008)   172.00M\n",
      "Tensor688                                      (4096, 11008)   172.00M\n",
      "Tensor689                                               (1,)   512.00B\n",
      "Tensor690                                            (4096,)    16.00K\n",
      "Tensor691                                            (4096,)    16.00K\n",
      "Tensor692                                               (1,)   512.00B\n",
      "Tensor693                                            (4096,)    16.00K\n",
      "Tensor694                                            (4096,)    16.00K\n",
      "Tensor695                                               (1,)   512.00B\n",
      "Tensor696                                       (4096, 4096)    64.00M\n",
      "Tensor697                                       (4096, 4096)    64.00M\n",
      "Tensor698                                               (1,)   512.00B\n",
      "Tensor699                                       (4096, 4096)    64.00M\n",
      "Tensor700                                       (4096, 4096)    64.00M\n",
      "Tensor701                                               (1,)   512.00B\n",
      "Tensor702                                       (4096, 4096)    64.00M\n",
      "Tensor703                                       (4096, 4096)    64.00M\n",
      "Tensor704                                               (1,)   512.00B\n",
      "Tensor705                                       (4096, 4096)    64.00M\n",
      "Tensor706                                       (4096, 4096)    64.00M\n",
      "Tensor707                                               (1,)   512.00B\n",
      "Tensor708                                      (11008, 4096)   172.00M\n",
      "Tensor709                                      (11008, 4096)   172.00M\n",
      "Tensor710                                               (1,)   512.00B\n",
      "Tensor711                                      (11008, 4096)   172.00M\n",
      "Tensor712                                      (11008, 4096)   172.00M\n",
      "Tensor713                                               (1,)   512.00B\n",
      "Tensor714                                      (4096, 11008)   172.00M\n",
      "Tensor715                                      (4096, 11008)   172.00M\n",
      "Tensor716                                               (1,)   512.00B\n",
      "Tensor717                                            (4096,)    16.00K\n",
      "Tensor718                                            (4096,)    16.00K\n",
      "Tensor719                                               (1,)   512.00B\n",
      "Tensor720                                            (4096,)    16.00K\n",
      "Tensor721                                            (4096,)    16.00K\n",
      "Tensor722                                               (1,)   512.00B\n",
      "Tensor723                                       (4096, 4096)    64.00M\n",
      "Tensor724                                       (4096, 4096)    64.00M\n",
      "Tensor725                                               (1,)   512.00B\n",
      "Tensor726                                       (4096, 4096)    64.00M\n",
      "Tensor727                                       (4096, 4096)    64.00M\n",
      "Tensor728                                               (1,)   512.00B\n",
      "Tensor729                                       (4096, 4096)    64.00M\n",
      "Tensor730                                       (4096, 4096)    64.00M\n",
      "Tensor731                                               (1,)   512.00B\n",
      "Tensor732                                       (4096, 4096)    64.00M\n",
      "Tensor733                                       (4096, 4096)    64.00M\n",
      "Tensor734                                               (1,)   512.00B\n",
      "Tensor735                                      (11008, 4096)   172.00M\n",
      "Tensor736                                      (11008, 4096)   172.00M\n",
      "Tensor737                                               (1,)   512.00B\n",
      "Tensor738                                      (11008, 4096)   172.00M\n",
      "Tensor739                                      (11008, 4096)   172.00M\n",
      "Tensor740                                               (1,)   512.00B\n",
      "Tensor741                                      (4096, 11008)   172.00M\n",
      "Tensor742                                      (4096, 11008)   172.00M\n",
      "Tensor743                                               (1,)   512.00B\n",
      "Tensor744                                            (4096,)    16.00K\n",
      "Tensor745                                            (4096,)    16.00K\n",
      "Tensor746                                               (1,)   512.00B\n",
      "Tensor747                                            (4096,)    16.00K\n",
      "Tensor748                                            (4096,)    16.00K\n",
      "Tensor749                                               (1,)   512.00B\n",
      "Tensor750                                       (4096, 4096)    64.00M\n",
      "Tensor751                                       (4096, 4096)    64.00M\n",
      "Tensor752                                               (1,)   512.00B\n",
      "Tensor753                                       (4096, 4096)    64.00M\n",
      "Tensor754                                       (4096, 4096)    64.00M\n",
      "Tensor755                                               (1,)   512.00B\n",
      "Tensor756                                       (4096, 4096)    64.00M\n",
      "Tensor757                                       (4096, 4096)    64.00M\n",
      "Tensor758                                               (1,)   512.00B\n",
      "Tensor759                                       (4096, 4096)    64.00M\n",
      "Tensor760                                       (4096, 4096)    64.00M\n",
      "Tensor761                                               (1,)   512.00B\n",
      "Tensor762                                      (11008, 4096)   172.00M\n",
      "Tensor763                                      (11008, 4096)   172.00M\n",
      "Tensor764                                               (1,)   512.00B\n",
      "Tensor765                                      (11008, 4096)   172.00M\n",
      "Tensor766                                      (11008, 4096)   172.00M\n",
      "Tensor767                                               (1,)   512.00B\n",
      "Tensor768                                      (4096, 11008)   172.00M\n",
      "Tensor769                                      (4096, 11008)   172.00M\n",
      "Tensor770                                               (1,)   512.00B\n",
      "Tensor771                                            (4096,)    16.00K\n",
      "Tensor772                                            (4096,)    16.00K\n",
      "Tensor773                                               (1,)   512.00B\n",
      "Tensor774                                            (4096,)    16.00K\n",
      "Tensor775                                            (4096,)    16.00K\n",
      "Tensor776                                               (1,)   512.00B\n",
      "Tensor777                                       (4096, 4096)    64.00M\n",
      "Tensor778                                       (4096, 4096)    64.00M\n",
      "Tensor779                                               (1,)   512.00B\n",
      "Tensor780                                       (4096, 4096)    64.00M\n",
      "Tensor781                                       (4096, 4096)    64.00M\n",
      "Tensor782                                               (1,)   512.00B\n",
      "Tensor783                                       (4096, 4096)    64.00M\n",
      "Tensor784                                       (4096, 4096)    64.00M\n",
      "Tensor785                                               (1,)   512.00B\n",
      "Tensor786                                       (4096, 4096)    64.00M\n",
      "Tensor787                                       (4096, 4096)    64.00M\n",
      "Tensor788                                               (1,)   512.00B\n",
      "Tensor789                                      (11008, 4096)   172.00M\n",
      "Tensor790                                      (11008, 4096)   172.00M\n",
      "Tensor791                                               (1,)   512.00B\n",
      "Tensor792                                      (11008, 4096)   172.00M\n",
      "Tensor793                                      (11008, 4096)   172.00M\n",
      "Tensor794                                               (1,)   512.00B\n",
      "Tensor795                                      (4096, 11008)   172.00M\n",
      "Tensor796                                      (4096, 11008)   172.00M\n",
      "Tensor797                                               (1,)   512.00B\n",
      "Tensor798                                            (4096,)    16.00K\n",
      "Tensor799                                            (4096,)    16.00K\n",
      "Tensor800                                               (1,)   512.00B\n",
      "Tensor801                                            (4096,)    16.00K\n",
      "Tensor802                                            (4096,)    16.00K\n",
      "Tensor803                                               (1,)   512.00B\n",
      "Tensor804                                       (4096, 4096)    64.00M\n",
      "Tensor805                                       (4096, 4096)    64.00M\n",
      "Tensor806                                               (1,)   512.00B\n",
      "Tensor807                                       (4096, 4096)    64.00M\n",
      "Tensor808                                       (4096, 4096)    64.00M\n",
      "Tensor809                                               (1,)   512.00B\n",
      "Tensor810                                       (4096, 4096)    64.00M\n",
      "Tensor811                                       (4096, 4096)    64.00M\n",
      "Tensor812                                               (1,)   512.00B\n",
      "Tensor813                                       (4096, 4096)    64.00M\n",
      "Tensor814                                       (4096, 4096)    64.00M\n",
      "Tensor815                                               (1,)   512.00B\n",
      "Tensor816                                      (11008, 4096)   172.00M\n",
      "Tensor817                                      (11008, 4096)   172.00M\n",
      "Tensor818                                               (1,)   512.00B\n",
      "Tensor819                                      (11008, 4096)   172.00M\n",
      "Tensor820                                      (11008, 4096)   172.00M\n",
      "Tensor821                                               (1,)   512.00B\n",
      "Tensor822                                      (4096, 11008)   172.00M\n",
      "Tensor823                                      (4096, 11008)   172.00M\n",
      "Tensor824                                               (1,)   512.00B\n",
      "Tensor825                                            (4096,)    16.00K\n",
      "Tensor826                                            (4096,)    16.00K\n",
      "Tensor827                                               (1,)   512.00B\n",
      "Tensor828                                            (4096,)    16.00K\n",
      "Tensor829                                            (4096,)    16.00K\n",
      "Tensor830                                               (1,)   512.00B\n",
      "Tensor831                                       (4096, 4096)    64.00M\n",
      "Tensor832                                       (4096, 4096)    64.00M\n",
      "Tensor833                                               (1,)   512.00B\n",
      "Tensor834                                       (4096, 4096)    64.00M\n",
      "Tensor835                                       (4096, 4096)    64.00M\n",
      "Tensor836                                               (1,)   512.00B\n",
      "Tensor837                                       (4096, 4096)    64.00M\n",
      "Tensor838                                       (4096, 4096)    64.00M\n",
      "Tensor839                                               (1,)   512.00B\n",
      "Tensor840                                       (4096, 4096)    64.00M\n",
      "Tensor841                                       (4096, 4096)    64.00M\n",
      "Tensor842                                               (1,)   512.00B\n",
      "Tensor843                                      (11008, 4096)   172.00M\n",
      "Tensor844                                      (11008, 4096)   172.00M\n",
      "Tensor845                                               (1,)   512.00B\n",
      "Tensor846                                      (11008, 4096)   172.00M\n",
      "Tensor847                                      (11008, 4096)   172.00M\n",
      "Tensor848                                               (1,)   512.00B\n",
      "Tensor849                                      (4096, 11008)   172.00M\n",
      "Tensor850                                      (4096, 11008)   172.00M\n",
      "Tensor851                                               (1,)   512.00B\n",
      "Tensor852                                            (4096,)    16.00K\n",
      "Tensor853                                            (4096,)    16.00K\n",
      "Tensor854                                               (1,)   512.00B\n",
      "Tensor855                                            (4096,)    16.00K\n",
      "Tensor856                                            (4096,)    16.00K\n",
      "Tensor857                                               (1,)   512.00B\n",
      "Tensor858                                       (4096, 4096)    64.00M\n",
      "Tensor859                                       (4096, 4096)    64.00M\n",
      "Tensor860                                               (1,)   512.00B\n",
      "Tensor861                                       (4096, 4096)    64.00M\n",
      "Tensor862                                       (4096, 4096)    64.00M\n",
      "Tensor863                                               (1,)   512.00B\n",
      "Tensor864                                       (4096, 4096)    64.00M\n",
      "Tensor865                                       (4096, 4096)    64.00M\n",
      "Tensor866                                               (1,)   512.00B\n",
      "Tensor867                                       (4096, 4096)    64.00M\n",
      "Tensor868                                       (4096, 4096)    64.00M\n",
      "Tensor869                                               (1,)   512.00B\n",
      "Tensor870                                      (11008, 4096)   172.00M\n",
      "Tensor871                                      (11008, 4096)   172.00M\n",
      "Tensor872                                               (1,)   512.00B\n",
      "Tensor873                                      (11008, 4096)   172.00M\n",
      "Tensor874                                      (11008, 4096)   172.00M\n",
      "Tensor875                                               (1,)   512.00B\n",
      "Tensor876                                      (4096, 11008)   172.00M\n",
      "Tensor877                                      (4096, 11008)   172.00M\n",
      "Tensor878                                               (1,)   512.00B\n",
      "Tensor879                                            (4096,)    16.00K\n",
      "Tensor880                                            (4096,)    16.00K\n",
      "Tensor881                                               (1,)   512.00B\n",
      "Tensor882                                            (4096,)    16.00K\n",
      "Tensor883                                            (4096,)    16.00K\n",
      "Tensor884                                               (1,)   512.00B\n",
      "Tensor885                                       (4096, 4096)    64.00M\n",
      "Tensor886                                       (4096, 4096)    64.00M\n",
      "Tensor887                                               (1,)   512.00B\n",
      "Tensor888                                       (4096, 4096)    64.00M\n",
      "Tensor889                                       (4096, 4096)    64.00M\n",
      "Tensor890                                               (1,)   512.00B\n",
      "Tensor891                                       (4096, 4096)    64.00M\n",
      "Tensor892                                       (4096, 4096)    64.00M\n",
      "Tensor893                                               (1,)   512.00B\n",
      "Tensor894                                       (4096, 4096)    64.00M\n",
      "Tensor895                                       (4096, 4096)    64.00M\n",
      "Tensor896                                               (1,)   512.00B\n",
      "Tensor897                                      (11008, 4096)   172.00M\n",
      "Tensor898                                      (11008, 4096)   172.00M\n",
      "Tensor899                                               (1,)   512.00B\n",
      "Tensor900                                      (11008, 4096)   172.00M\n",
      "Tensor901                                      (11008, 4096)   172.00M\n",
      "Tensor902                                               (1,)   512.00B\n",
      "Tensor903                                      (4096, 11008)   172.00M\n",
      "Tensor904                                      (4096, 11008)   172.00M\n",
      "Tensor905                                               (1,)   512.00B\n",
      "Tensor906                                            (4096,)    16.00K\n",
      "Tensor907                                            (4096,)    16.00K\n",
      "Tensor908                                               (1,)   512.00B\n",
      "Tensor909                                            (4096,)    16.00K\n",
      "Tensor910                                            (4096,)    16.00K\n",
      "Tensor911                                               (1,)   512.00B\n",
      "Tensor912                                       (4096, 4096)    64.00M\n",
      "Tensor913                                       (4096, 4096)    64.00M\n",
      "Tensor914                                               (1,)   512.00B\n",
      "Tensor915                                       (4096, 4096)    64.00M\n",
      "Tensor916                                       (4096, 4096)    64.00M\n",
      "Tensor917                                               (1,)   512.00B\n",
      "Tensor918                                       (4096, 4096)    64.00M\n",
      "Tensor919                                       (4096, 4096)    64.00M\n",
      "Tensor920                                               (1,)   512.00B\n",
      "Tensor921                                       (4096, 4096)    64.00M\n",
      "Tensor922                                       (4096, 4096)    64.00M\n",
      "Tensor923                                               (1,)   512.00B\n",
      "Tensor924                                      (11008, 4096)   172.00M\n",
      "Tensor925                                      (11008, 4096)   172.00M\n",
      "Tensor926                                               (1,)   512.00B\n",
      "Tensor927                                      (11008, 4096)   172.00M\n",
      "Tensor928                                      (11008, 4096)   172.00M\n",
      "Tensor929                                               (1,)   512.00B\n",
      "Tensor930                                      (4096, 11008)   172.00M\n",
      "Tensor931                                      (4096, 11008)   172.00M\n",
      "Tensor932                                               (1,)   512.00B\n",
      "Tensor933                                            (4096,)    16.00K\n",
      "Tensor934                                            (4096,)    16.00K\n",
      "Tensor935                                               (1,)   512.00B\n",
      "Tensor936                                            (4096,)    16.00K\n",
      "Tensor937                                            (4096,)    16.00K\n",
      "Tensor938                                               (1,)   512.00B\n",
      "Tensor939                                       (4096, 4096)    64.00M\n",
      "Tensor940                                       (4096, 4096)    64.00M\n",
      "Tensor941                                               (1,)   512.00B\n",
      "Tensor942                                       (4096, 4096)    64.00M\n",
      "Tensor943                                       (4096, 4096)    64.00M\n",
      "Tensor944                                       (4096, 4096)    64.00M\n",
      "model.layers.30.self_attn.v_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.30.self_attn.k_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.30.self_attn.q_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.29.post_attention_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.layers.29.input_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.layers.29.mlp.down_proj.weight.grad       (4096, 11008)     0.00B\n",
      "model.layers.29.mlp.up_proj.weight.grad        (11008, 4096)     0.00B\n",
      "model.layers.29.mlp.gate_proj.weight.grad       (11008, 4096)     0.00B\n",
      "model.layers.29.self_attn.o_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.29.self_attn.v_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.29.self_attn.k_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.29.self_attn.q_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.28.post_attention_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.layers.28.input_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.layers.28.mlp.down_proj.weight.grad       (4096, 11008)     0.00B\n",
      "model.layers.28.mlp.up_proj.weight.grad        (11008, 4096)     0.00B\n",
      "model.layers.28.mlp.gate_proj.weight.grad       (11008, 4096)     0.00B\n",
      "model.layers.28.self_attn.o_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.28.self_attn.v_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.28.self_attn.k_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.28.self_attn.q_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.27.post_attention_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.layers.27.input_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.layers.27.mlp.down_proj.weight.grad       (4096, 11008)     0.00B\n",
      "model.layers.27.mlp.up_proj.weight.grad        (11008, 4096)     0.00B\n",
      "model.layers.27.mlp.gate_proj.weight.grad       (11008, 4096)     0.00B\n",
      "model.layers.27.self_attn.o_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.27.self_attn.v_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.27.self_attn.k_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.27.self_attn.q_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.26.post_attention_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.layers.26.input_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.layers.26.mlp.down_proj.weight.grad       (4096, 11008)     0.00B\n",
      "model.layers.26.mlp.up_proj.weight.grad        (11008, 4096)     0.00B\n",
      "model.layers.26.mlp.gate_proj.weight.grad       (11008, 4096)     0.00B\n",
      "model.layers.26.self_attn.o_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.26.self_attn.v_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.26.self_attn.k_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.26.self_attn.q_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.25.post_attention_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.layers.25.input_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.layers.25.mlp.down_proj.weight.grad       (4096, 11008)     0.00B\n",
      "model.layers.25.mlp.up_proj.weight.grad        (11008, 4096)     0.00B\n",
      "model.layers.25.mlp.gate_proj.weight.grad       (11008, 4096)     0.00B\n",
      "model.layers.25.self_attn.o_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.25.self_attn.v_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.25.self_attn.k_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.25.self_attn.q_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.24.post_attention_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.layers.24.input_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.layers.24.mlp.down_proj.weight.grad       (4096, 11008)     0.00B\n",
      "model.layers.24.mlp.up_proj.weight.grad        (11008, 4096)     0.00B\n",
      "model.layers.24.mlp.gate_proj.weight.grad       (11008, 4096)     0.00B\n",
      "model.layers.24.self_attn.o_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.24.self_attn.v_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.24.self_attn.k_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.24.self_attn.q_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.23.post_attention_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.layers.23.input_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.layers.23.mlp.down_proj.weight.grad       (4096, 11008)     0.00B\n",
      "model.layers.23.mlp.up_proj.weight.grad        (11008, 4096)     0.00B\n",
      "model.layers.23.mlp.gate_proj.weight.grad       (11008, 4096)     0.00B\n",
      "model.layers.23.self_attn.o_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.23.self_attn.v_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.23.self_attn.k_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.23.self_attn.q_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.22.post_attention_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.layers.22.input_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.layers.22.mlp.down_proj.weight.grad       (4096, 11008)     0.00B\n",
      "model.layers.22.mlp.up_proj.weight.grad        (11008, 4096)     0.00B\n",
      "model.layers.22.mlp.gate_proj.weight.grad       (11008, 4096)     0.00B\n",
      "model.layers.22.self_attn.o_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.22.self_attn.v_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.22.self_attn.k_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.22.self_attn.q_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.21.post_attention_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.layers.21.input_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.layers.21.mlp.down_proj.weight.grad       (4096, 11008)     0.00B\n",
      "model.layers.21.mlp.up_proj.weight.grad        (11008, 4096)     0.00B\n",
      "model.layers.21.mlp.gate_proj.weight.grad       (11008, 4096)     0.00B\n",
      "model.layers.21.self_attn.o_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.21.self_attn.v_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.21.self_attn.k_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.21.self_attn.q_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.20.post_attention_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.layers.20.input_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.layers.20.mlp.down_proj.weight.grad       (4096, 11008)     0.00B\n",
      "model.layers.20.mlp.up_proj.weight.grad        (11008, 4096)     0.00B\n",
      "model.layers.20.mlp.gate_proj.weight.grad       (11008, 4096)     0.00B\n",
      "model.layers.20.self_attn.o_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.20.self_attn.v_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.20.self_attn.k_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.20.self_attn.q_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.19.post_attention_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.layers.19.input_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.layers.19.mlp.down_proj.weight.grad       (4096, 11008)     0.00B\n",
      "model.layers.19.mlp.up_proj.weight.grad        (11008, 4096)     0.00B\n",
      "model.layers.19.mlp.gate_proj.weight.grad       (11008, 4096)     0.00B\n",
      "model.layers.19.self_attn.o_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.19.self_attn.v_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.19.self_attn.k_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.19.self_attn.q_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.18.post_attention_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.layers.18.input_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.layers.18.mlp.down_proj.weight.grad       (4096, 11008)     0.00B\n",
      "model.layers.18.mlp.up_proj.weight.grad        (11008, 4096)     0.00B\n",
      "model.layers.18.mlp.gate_proj.weight.grad       (11008, 4096)     0.00B\n",
      "model.layers.18.self_attn.o_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.18.self_attn.v_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.18.self_attn.k_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.18.self_attn.q_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.17.post_attention_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.layers.17.input_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.layers.17.mlp.down_proj.weight.grad       (4096, 11008)     0.00B\n",
      "model.layers.17.mlp.up_proj.weight.grad        (11008, 4096)     0.00B\n",
      "model.layers.17.mlp.gate_proj.weight.grad       (11008, 4096)     0.00B\n",
      "model.layers.17.self_attn.o_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.17.self_attn.v_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.17.self_attn.k_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.17.self_attn.q_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.16.post_attention_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.layers.16.input_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.layers.16.mlp.down_proj.weight.grad       (4096, 11008)     0.00B\n",
      "model.layers.16.mlp.up_proj.weight.grad        (11008, 4096)     0.00B\n",
      "model.layers.16.mlp.gate_proj.weight.grad       (11008, 4096)     0.00B\n",
      "model.layers.16.self_attn.o_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.16.self_attn.v_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.16.self_attn.k_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.16.self_attn.q_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.15.post_attention_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.layers.15.input_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.layers.15.mlp.down_proj.weight.grad       (4096, 11008)     0.00B\n",
      "model.layers.15.mlp.up_proj.weight.grad        (11008, 4096)     0.00B\n",
      "model.layers.15.mlp.gate_proj.weight.grad       (11008, 4096)     0.00B\n",
      "model.layers.15.self_attn.o_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.15.self_attn.v_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.15.self_attn.k_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.15.self_attn.q_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.14.post_attention_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.layers.14.input_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.layers.14.mlp.down_proj.weight.grad       (4096, 11008)     0.00B\n",
      "model.layers.14.mlp.up_proj.weight.grad        (11008, 4096)     0.00B\n",
      "model.layers.14.mlp.gate_proj.weight.grad       (11008, 4096)     0.00B\n",
      "model.layers.14.self_attn.o_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.14.self_attn.v_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.14.self_attn.k_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.14.self_attn.q_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.13.post_attention_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.layers.13.input_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.layers.13.mlp.down_proj.weight.grad       (4096, 11008)     0.00B\n",
      "model.layers.13.mlp.up_proj.weight.grad        (11008, 4096)     0.00B\n",
      "model.layers.13.mlp.gate_proj.weight.grad       (11008, 4096)     0.00B\n",
      "model.layers.13.self_attn.o_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.13.self_attn.v_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.13.self_attn.k_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.13.self_attn.q_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.12.post_attention_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.layers.12.input_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.layers.12.mlp.down_proj.weight.grad       (4096, 11008)     0.00B\n",
      "model.layers.12.mlp.up_proj.weight.grad        (11008, 4096)     0.00B\n",
      "model.layers.12.mlp.gate_proj.weight.grad       (11008, 4096)     0.00B\n",
      "model.layers.12.self_attn.o_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.12.self_attn.v_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.12.self_attn.k_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.12.self_attn.q_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.11.post_attention_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.layers.11.input_layernorm.weight.grad             (4096,)     0.00B\n",
      "model.layers.11.mlp.down_proj.weight.grad       (4096, 11008)     0.00B\n",
      "model.layers.11.mlp.up_proj.weight.grad        (11008, 4096)     0.00B\n",
      "model.layers.11.mlp.gate_proj.weight.grad       (11008, 4096)     0.00B\n",
      "model.layers.11.self_attn.o_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.11.self_attn.v_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.11.self_attn.k_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.11.self_attn.q_proj.weight.grad        (4096, 4096)     0.00B\n",
      "model.layers.10.post_attention_layernorm.weight.grad             (4096,)     0.00B\n",
      "Tensor945                                    (1, 32, 2, 128)     0.00B\n",
      "Tensor946                                    (1, 32, 2, 128)    32.00K\n",
      "Tensor947                                    (1, 32, 2, 128)     0.00B\n",
      "Tensor948                                    (1, 32, 2, 128)    32.00K\n",
      "Tensor949                                    (1, 32, 2, 128)     0.00B\n",
      "Tensor950                                    (1, 32, 2, 128)    32.00K\n",
      "Tensor951                                    (1, 32, 2, 128)     0.00B\n",
      "Tensor952                                    (1, 32, 2, 128)    32.00K\n",
      "Tensor953                                    (1, 32, 2, 128)     0.00B\n",
      "Tensor954                                    (1, 32, 2, 128)    32.00K\n",
      "Tensor955                                    (1, 32, 2, 128)     0.00B\n",
      "Tensor956                                    (1, 32, 2, 128)    32.00K\n",
      "Tensor957                                    (1, 32, 2, 128)     0.00B\n",
      "Tensor958                                    (1, 32, 2, 128)    32.00K\n",
      "Tensor959                                    (1, 32, 2, 128)     0.00B\n",
      "Tensor960                                    (1, 32, 2, 128)    32.00K\n",
      "Tensor961                                    (1, 32, 2, 128)     0.00B\n",
      "Tensor962                                    (1, 32, 2, 128)    32.00K\n",
      "Tensor963                                    (1, 32, 2, 128)     0.00B\n",
      "Tensor964                                    (1, 32, 2, 128)    32.00K\n",
      "Tensor965                                    (1, 32, 2, 128)     0.00B\n",
      "Tensor966                                    (1, 32, 2, 128)    32.00K\n",
      "Tensor967                                    (1, 32, 2, 128)     0.00B\n",
      "Tensor968                                    (1, 32, 2, 128)    32.00K\n",
      "Tensor969                                    (1, 32, 2, 128)     0.00B\n",
      "Tensor970                                    (1, 32, 2, 128)    32.00K\n",
      "Tensor971                                    (1, 32, 2, 128)     0.00B\n",
      "Tensor972                                    (1, 32, 2, 128)    32.00K\n",
      "Tensor973                                    (1, 32, 2, 128)     0.00B\n",
      "Tensor974                                    (1, 32, 2, 128)    32.00K\n",
      "Tensor975                                    (1, 32, 2, 128)     0.00B\n",
      "Tensor976                                    (1, 32, 2, 128)    32.00K\n",
      "Tensor977                                    (1, 32, 2, 128)     0.00B\n",
      "Tensor978                                    (1, 32, 2, 128)    32.00K\n",
      "Tensor979                                    (1, 32, 2, 128)     0.00B\n",
      "Tensor980                                    (1, 32, 2, 128)    32.00K\n",
      "Tensor981                                    (1, 32, 2, 128)     0.00B\n",
      "Tensor982                                    (1, 32, 2, 128)    32.00K\n",
      "Tensor983                                    (1, 32, 2, 128)     0.00B\n",
      "Tensor984                                    (1, 32, 2, 128)    32.00K\n",
      "Tensor985                                    (1, 32, 2, 128)     0.00B\n",
      "Tensor986                                    (1, 32, 2, 128)    32.00K\n",
      "Tensor987                                    (1, 32, 2, 128)     0.00B\n",
      "Tensor988                                    (1, 32, 2, 128)    32.00K\n",
      "Tensor989                                    (1, 32, 2, 128)     0.00B\n",
      "Tensor990                                    (1, 32, 2, 128)    32.00K\n",
      "Tensor991                                    (1, 32, 2, 128)     0.00B\n",
      "Tensor992                                    (1, 32, 2, 128)    32.00K\n",
      "Tensor993                                    (1, 32, 2, 128)     0.00B\n",
      "Tensor994                                    (1, 32, 2, 128)    32.00K\n",
      "Tensor995                                    (1, 32, 2, 128)     0.00B\n",
      "Tensor996                                    (1, 32, 2, 128)    32.00K\n",
      "Tensor997                                    (1, 32, 2, 128)     0.00B\n",
      "Tensor998                                    (1, 32, 2, 128)    32.00K\n",
      "Tensor999                                    (1, 32, 2, 128)     0.00B\n",
      "Tensor1000                                   (1, 32, 2, 128)    32.00K\n",
      "Tensor1001                                   (1, 32, 2, 128)     0.00B\n",
      "Tensor1002                                   (1, 32, 2, 128)    32.00K\n",
      "Tensor1003                                   (1, 32, 2, 128)     0.00B\n",
      "Tensor1004                                   (1, 32, 2, 128)    32.00K\n",
      "Tensor1005                                   (1, 32, 2, 128)     0.00B\n",
      "Tensor1006                                   (1, 32, 2, 128)    32.00K\n",
      "Tensor1007                                              (1,)   512.00B\n",
      "-------------------------------------------------------------------------------\n",
      "Total Tensors: 33692930922 \tUsed Memory: 100.41G\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xxc13\\anaconda3\\Lib\\site-packages\\pytorch_memlab\\mem_reporter.py:65: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead\n",
      "  tensors = [obj for obj in objects if isinstance(obj, torch.Tensor)]\n",
      "C:\\Users\\xxc13\\anaconda3\\Lib\\site-packages\\pytorch_memlab\\mem_reporter.py:95: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  fact_numel = tensor.storage().size()\n"
     ]
    }
   ],
   "source": [
    "model_directory = r\"Z:/llmfile/Llama-2-7B-hf/models--meta-llama--Llama-2-7b-hf/snapshots/01c7f73d771dfac7d292323805ebc428287df4f9\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_directory)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_directory)\n",
    "\n",
    "# 设置优化器(Adam)和 GradScaler 用于混合精度\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "scaler = GradScaler()\n",
    "\n",
    "# 初始输入和标签\n",
    "input_text = \"Hello\"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "labels = input_ids.clone()  # 使用输入作为标签\n",
    "\n",
    "reporter = MemReporter(model)\n",
    "\n",
    "# 先执行一次前向和反向传播，确保 scaler 正常初始化\n",
    "print(\"==初始化一下==\")\n",
    "model.train()\n",
    "optimizer.zero_grad()\n",
    "\n",
    "with autocast(\"cuda\"):\n",
    "    outputs = model(input_ids, labels=labels)\n",
    "    loss = outputs.loss\n",
    "\n",
    "scaler.scale(loss).backward()  # 反向传播以初始化 GradScaler\n",
    "\n",
    "# 执行优化器更新并监控内存\n",
    "print(\"==OptimizerMemoryUsage==\")\n",
    "scaler.step(optimizer)  # 执行优化器更新\n",
    "scaler.update()  # 更新 scaler 状态\n",
    "reporter.report()  # 记录优化器更新后的内存使用情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cd3c018-1ee0-4575-ba7f-9d99c90d110a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 清理内存\n",
    "del outputs, loss\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db217fe7-da1b-4f33-b7dc-331446f9263b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff82a2b-c02b-4ccd-a697-758ce7e35a34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
