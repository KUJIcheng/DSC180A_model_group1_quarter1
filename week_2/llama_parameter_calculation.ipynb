{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# V: Vocabulary Size; H: Hidden Dimension; I: Intermediate Size; N: Number of Attention Blocks; g: gorup number\n",
        "def llama_calculate_layers(V, H, I, N, g = None):\n",
        "    # Embedding Layer\n",
        "    embedding_layer = V * H\n",
        "\n",
        "    # RMS Norm Layer\n",
        "    rms_norm_layer = H\n",
        "\n",
        "    # Final Projection\n",
        "    final_proj = H * V\n",
        "\n",
        "    # Query (Q), Key (K), Value (V)\n",
        "    q = H * H\n",
        "    if g == None:\n",
        "      k = H * H\n",
        "      v = H * H\n",
        "    else:\n",
        "      k = H * H / g\n",
        "      v = H * H / g\n",
        "\n",
        "    # Output (O)\n",
        "    o = H * H\n",
        "\n",
        "    # MLP calculation\n",
        "    mlp = 2 * H * I + I * H\n",
        "\n",
        "    # Attention Blocks\n",
        "    attention_blocks = N * (2 * rms_norm_layer + q + k + v + o + mlp)\n",
        "\n",
        "    # All Layers (Sum of all components)\n",
        "    all_layers = embedding_layer + attention_blocks + rms_norm_layer + final_proj\n",
        "\n",
        "    return float(all_layers)"
      ],
      "metadata": {
        "id": "JGlGcijBFK0i"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LLama2 7B\n",
        "llama_7b = llama_calculate_layers(32000, 4096, 11008, 32)\n",
        "print(f\"llama_7b parameter: {llama_7b}\")\n",
        "\n",
        "# LLama3 8B\n",
        "llama_8b = llama_calculate_layers(128256, 4096, 14336, 32, g = 4)\n",
        "print(f\"llama_8b parameter: {llama_8b}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHKjIQMO124A",
        "outputId": "dd11e26a-ea68-43ca-ac4b-bb7b529a42fe"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "llama_7b parameter: 6738415616.0\n",
            "llama_8b parameter: 8030261248.0\n"
          ]
        }
      ]
    }
  ]
}