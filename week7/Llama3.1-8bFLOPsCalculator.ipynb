{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fec7d537-30e9-434f-9988-0658c58c6df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2248879235923968 6746637707771904\n"
     ]
    }
   ],
   "source": [
    "# Llama3.1-8b FLOPs Calculator\n",
    "\n",
    "# batch size is 2, gradient accumulation step is 16, with 4 GPU, where 2*16*4=128\n",
    "b = 128   # Batch size \n",
    "s = 1024  # Sequence length\n",
    "\n",
    "# Parameter of the Llama3.1-8b\n",
    "v = 128256  # Vocabulary size\n",
    "n = 8  # Number of attention heads\n",
    "h = 4096  # Hidden state dimension\n",
    "i = 14336  # SwiGLU projection dimension\n",
    "N = 32  # Number of layers\n",
    "\n",
    "# FLOPs calculation for one forward pass\n",
    "flops_per_forward = N * (6*b*s*h**2 + 4*b*s**2*h + 3*b*s**2*n + 2*b*s*h**2) + N * (6*b*s*h*i) + 2*b*s*h*v\n",
    "\n",
    "# Forward-backward pass is roughly 3 times the forward pass FLOPs\n",
    "flops_per_forward_backward = 3 * flops_per_forward\n",
    "\n",
    "print(flops_per_forward, flops_per_forward_backward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "299be0ff-cd24-4b3b-9bed-e67231bd39d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6746.637707771904"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_TFLOPs_per_iteration = flops_per_forward_backward / 10 ** 12\n",
    "total_TFLOPs_per_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "07c1a688-d45b-4fd7-ae26-3b043e80f50e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42149.532"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4 GPU; Each of the GPUs' peak TFLOPS in FP16 is 149.7; One iteration need 70.39s in average\n",
    "# The result represent each iteration, assuming GPUs are fully used, TFLOPs are cost in GPUs\n",
    "GPU_TFLOPs_per_interation = 4 * 149.7 * 70.39\n",
    "GPU_TFLOPs_per_interation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "47f617fc-5eda-4a72-a1f6-634940d7d407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1600643562963381"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MFU = total_TFLOPs_per_iteration / GPU_TFLOPs_per_interation\n",
    "MFU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "92cebde8-7d50-4585-91f3-43bb6f9df547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.00643562963381"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MFU * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10542dc4-2044-4bbd-9119-fe0ccd2a2abc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
